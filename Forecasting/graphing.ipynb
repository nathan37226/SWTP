{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def makeNullRects(dates, y):\n",
    "    '''This function returns a list of matplotlib.patches.Rectangles where\n",
    "    np.nan values are present in the y array. If values are consecutive,\n",
    "    the rectangles will widen as needed.\n",
    "    Note that this function is made for a figure with an x-axis of dates\n",
    "    Input:\n",
    "        dates: x axis date time values\n",
    "        y: y axis range values as np.array, contains np.nan values\n",
    "\n",
    "    Returns:\n",
    "        list of matplotlib.patches.Rectangles located where\n",
    "        y has np.nan values.\n",
    "\n",
    "    Rectangle Parameters in function:\n",
    "        opacityCoeff: how solid rectangles appear\n",
    "        longRectColor: the color of the rectangles with >=7 width\n",
    "        shortRectColor: the color of the rectanges with <7 width\n",
    "    '''\n",
    "    # setting up rectangle parameters\n",
    "    opacityCoeff = 0.5\n",
    "    longRectColor = \"red\"\n",
    "    shortRectColor = \"magenta\"\n",
    "\n",
    "    # prep work for creating rectangles for nan values\n",
    "    index = 0\n",
    "    yMax = np.nanmax(y)\n",
    "    yMin = np.nanmin(y)\n",
    "    rectHeight = yMax - yMin\n",
    "    yRectCoor = yMin\n",
    "    allRects = []   # this is what will be returned\n",
    "\n",
    "    # creating rectangle patches\n",
    "    while index < len(y):\n",
    "\n",
    "        # if nan exists, then need to create a rectangle patch\n",
    "        if np.isnan(y[index]):\n",
    "            xRectCoorIndex = index - 1\n",
    "\n",
    "            # condition for if first y value is nan\n",
    "            if index == 0:\n",
    "                xRectCoorIndex += 1\n",
    "            \n",
    "            # condition for if last y value is nan, assumes y is not len 2\n",
    "            elif index + 1 == len(y):\n",
    "                xRectCoor = mdates.date2num(dates[xRectCoorIndex])\n",
    "                coords = (xRectCoor, yRectCoor)\n",
    "                width = mdates.date2num(dates[xRectCoorIndex + 1]) - mdates.date2num(dates[xRectCoorIndex])\n",
    "                allRects.append(mpatches.Rectangle(coords, width, rectHeight, color=shortRectColor, alpha=opacityCoeff))\n",
    "                break\n",
    "                \n",
    "            # all other cases\n",
    "            xRectCoor = mdates.date2num(dates[xRectCoorIndex])\n",
    "\n",
    "            # checking finding how long the rectangle needs to be--how many consecutive null values\n",
    "            index += 1\n",
    "            while np.isnan(y[index]):\n",
    "                index += 1\n",
    "            rightEdgeIndex = mdates.date2num(dates[index])\n",
    "\n",
    "            # making rectangle\n",
    "            coords = (xRectCoor, yRectCoor)\n",
    "            width = rightEdgeIndex - xRectCoor\n",
    "            color = shortRectColor\n",
    "            if index - xRectCoorIndex > 5:\n",
    "                color = longRectColor\n",
    "            allRects.append(mpatches.Rectangle(coords, width, rectHeight, color=color, alpha=opacityCoeff))\n",
    "\n",
    "        else:\n",
    "            index += 1\n",
    "\n",
    "    return allRects\n",
    "\n",
    "def visualizeMissingValues(dates, arr, fig, ax, wantToMakeNullRects = True):\n",
    "    '''This function plots an array of values with datetime x axis values onto\n",
    "    a given axis, showing patches of null values if present.\n",
    "\n",
    "    Input:\n",
    "        dates: a numpy array of datetime objs that are the x-axis for the array with missing data to plot\n",
    "        arr: a numpy array that has missing data\n",
    "        fig: a matplotlib figure that contains the axis with the plot\n",
    "        ax: a matplotlib axis that will be plotted upon\n",
    "\n",
    "    Returns:\n",
    "        fig: edited matplotlib figure\n",
    "        ax: edited matplotlib axis\n",
    "    '''\n",
    "    ax.plot(dates, arr)\n",
    "\n",
    "    if wantToMakeNullRects:\n",
    "        rects = makeNullRects(dates, arr)\n",
    "        for rect in rects:\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    formatter = mdates.ConciseDateFormatter(ax.xaxis.get_major_locator(), formats=[\"%Y\", \"%Y-%b\", \"%b-%d\", \"%d %H:%M\", \"%d %H:%M\", \"%H:%M\"])\n",
    "    locator = mdates.AutoDateLocator()\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    return fig, ax\n",
    "\n",
    "def plotImputedData(dates, nullArr, imputedArr, ax):\n",
    "    '''This graph plots imputed data as a green dashed line on a given\n",
    "    matplotlib axis.\n",
    "\n",
    "    Input:\n",
    "        dates: a numpy array of datetime objs that are the x-axis for the array with missing data to plot\n",
    "        nullArr: a numpy array that has missing data\n",
    "        imputedArr: a numpy array that has some of the missing values imputed\n",
    "        ax: a matplotlib axis that will be plotted upon\n",
    "    \n",
    "    Returns:\n",
    "        ax: edited matplotlib axis\n",
    "    '''\n",
    "    index = 0\n",
    "    while index < len(nullArr):                                 # looping through arr since it has the null values\n",
    "        if np.isnan(nullArr[index]):\n",
    "            # getting the width of the null area\n",
    "            lenForward = 0\n",
    "            while np.isnan(nullArr[index + lenForward]):\n",
    "                lenForward += 1\n",
    "\n",
    "            # domain to plot is [index-1, index+lenforward]\n",
    "            domain = list(range(index-1, index+lenForward+1))\n",
    "            datesToPlot = [dates[i] for i in domain]\n",
    "            pointsToPlot = [imputedArr[i] for i in domain]\n",
    "            ax.plot(datesToPlot, pointsToPlot, \"g--\")       # green dashed line\n",
    "\n",
    "            # moving index forward past null gap\n",
    "            index += lenForward\n",
    "        else:\n",
    "            index += 1\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "# feature = \"SWTP Total Influent Flow\"\n",
    "# feature = \"SWTP Plant 2 Influent Flow\"\n",
    "# feature = \"SW_Peak_Flow\"\n",
    "# feature = \"SWTP Plant 1 Gravity Flow\"\n",
    "# feature = \"Total 168 Hour Rainfall Aggregate\"\n",
    "# feature = \"Ozark Aquifer Depth to Water Level (ft)\"\n",
    "# feature = \"Springfield Plateau Aquifer Depth to Water Level (ft)\"\n",
    "# feature = \"James Gauge Height (ft)\"\n",
    "# feature = \"Wilsons Gauge Height (ft)\"\n",
    "# feature = \"Fire 168 Hour Rainfall Aggregate\"\n",
    "feature = \"Fire Rainfall (in)\"\n",
    "# feature = \"HourlyPressureChange\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Joined Influent and Rainfall and Weather and Groundwater and Creek Gauge.csv\", parse_dates=[\"DateTime\"])\n",
    "# df = pd.read_csv(\"Small Gap Imputed Data.csv\", parse_dates=[\"DateTime\"])\n",
    "# df = pd.read_csv(\"Small Gap Imputed Data Editted.csv\", parse_dates=[\"DateTime\"])\n",
    "# df[\"SWTP Total Influent Flow\"] = np.array([np.nan if x < 3.7 else x for x in df[\"SWTP Total Influent Flow\"]])\n",
    "\n",
    "\n",
    "# imputedDf = pd.read_csv(\"Small Gap Imputed Data.csv\")\n",
    "# imputedDf = pd.read_csv(\"Small Gap Imputed Data Editted.csv\")\n",
    "# imputedDf = pd.read_csv(\"test.csv\")\n",
    "imputedDf = pd.read_csv(\"Imputed Data.csv\")\n",
    "# imputedDf = pd.read_csv(\"New Imputed Data.csv\")\n",
    "\n",
    "\n",
    "dates = np.array(df[\"DateTime\"])\n",
    "imputedArr = np.array(imputedDf[feature])\n",
    "nullArr = deepcopy(np.array(df[feature]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig, ax = visualizeMissingValues(dates, nullArr, fig, ax)\n",
    "ax = plotImputedData(dates, nullArr, imputedArr, ax)\n",
    "# ax = plotValidatedValues(ax)\n",
    "# ax.scatter(testDf[\"DateTime\"], testDf[testDf.columns[-1]], s=8, color=\"red\", marker=\"x\")\n",
    "ax.set_ylabel(feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_inv: (8760, 24)\n",
      "test_y_inv: (8760, 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib qt\n",
    "\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def sliding_window(X, y, n_test, slide):\n",
    "    split_point = X.shape[0] - n_test + slide\n",
    "    train_X , train_y = X[:split_point, :] , y[:split_point, :]\n",
    "    test_X , test_y = X[split_point:, :] , y[split_point:, :]\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "def invNormalize(arr, minimum, maximum):\n",
    "    return (maximum - minimum) * arr + minimum\n",
    "\n",
    "def predict(model, test_X, test_y, fullData = False):\n",
    "    # to be able to inverse scale predictions\n",
    "    df = pd.read_csv(\"Train and Test Data.csv\", usecols=[\"SWTP Total Influent Flow\"])\n",
    "    if fullData:\n",
    "        df = pd.read_csv(\"Imputed Data.csv\", usecols=[\"SWTP Total Influent Flow\"])\n",
    "    arr = np.array(df[\"SWTP Total Influent Flow\"])\n",
    "    maximum = np.max(arr)\n",
    "    minimum = np.min(arr)\n",
    "\n",
    "    #predictions and rescaling to [min, max]\n",
    "    y_pred = model.predict(test_X)\n",
    "    y_pred_inv = np.array([invNormalize(x, minimum, maximum) for x in y_pred])\n",
    "    test_y_inv = np.array([invNormalize(x, minimum, maximum) for x in test_y])\n",
    "    print(\"y_pred_inv:\",y_pred_inv.shape)\n",
    "    print(\"test_y_inv:\",y_pred_inv.shape)\n",
    "    \n",
    "    return y_pred_inv, test_y_inv\n",
    "\n",
    "\n",
    "# features = ['SWTP Total Influent Flow', 'Fire Rainfall (in)', 'Bingham Rainfall (in)']\n",
    "# features = ['SWTP Total Influent Flow', 'Fire Rainfall (in)', 'Bingham Rainfall (in)', 'SWTP Plant 1 Gravity Flow']\n",
    "features = ['SWTP Total Influent Flow', 'Fire Rainfall (in)', 'Bingham Rainfall (in)', \n",
    "            \"Ozark Aquifer Depth to Water Level (ft)\", \"James Gauge Height (ft)\", 'HourlyStationPressure']\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"Imputed Data Shifted Rain.csv\", usecols=features)\n",
    "arr = np.array(dataset[\"SWTP Total Influent Flow\"])\n",
    "dataset[\"Target\"] = arr         # adding another influent flow feature so that past values can be used to predict future values\n",
    "values = dataset.values\n",
    "\n",
    "# linear transformation of each feature from [min, max] to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# n_steps_in = 48\n",
    "n_steps_in = 36\n",
    "n_steps_out = 24\n",
    "X, y = split_sequences(scaled, n_steps_in, n_steps_out)\n",
    "train_X, train_y, test_X, test_y = sliding_window(X, y, 8760, 0)    # a full year of data\n",
    "\n",
    "# modelPath = \"48 hour epoch tuning\\\\keras_tuner_attempt14\\\\model\"\n",
    "# modelPath = \"36 hour epoch tuning\\\\keras_tuner_attempt7\\\\model\"\n",
    "# modelPath = \"feature tuning\\\\subset 1\\\\keras_tuner_attempt3\\\\model\" # did v well in long term\n",
    "# modelPath = \"feature tuning\\\\extraneous\\\\keras_tuner_attempt8\\\\model\" # avg mse of 58.5759\n",
    "modelPath = \"feature tuning\\\\subset 5\\\\36 hours\\\\keras_tuner_attempt1\\\\model\"     #avg mse of 52.9312\n",
    "model = keras.models.load_model(modelPath)\n",
    "y_pred_inv, y_test_inv = predict(model, test_X, test_y, True)\n",
    "\n",
    "x = list(range(len(y_pred_inv)))\n",
    "y = [mean_squared_error(y_pred_inv[i], y_test_inv[i]) for i in range(len(y_pred_inv))]\n",
    "\n",
    "\n",
    "\n",
    "# plotting the mse of 24 hour future predictions\n",
    "df = pd.read_csv(\"Imputed Data.csv\", usecols=[\"DateTime\", \"Fire Rainfall (in)\", \"Fire 168 Hour Rainfall Aggregate\"], parse_dates=[\"DateTime\"])\n",
    "dates = np.array(df[\"DateTime\"])\n",
    "dates = dates[-1*test_y.shape[0]-24:-24]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "formatter = mdates.ConciseDateFormatter(ax.xaxis.get_major_locator(), formats=[\"%Y\", \"%Y-%b\", \"%b-%d\", \"%d %H:%M\", \"%d %H:%M\", \"%H:%M\"])\n",
    "locator = mdates.AutoDateLocator()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "ax.set_title(\"RMSE of 24 Hour Forecasts per Hour\", fontsize=20)\n",
    "ax.set_ylabel(\"RMSE\", fontsize=16)\n",
    "ax.plot(dates, np.sqrt(y))  # root mean square error\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyRMSE = np.sqrt(y)\n",
    "# plt.hist(hourlyRMSE, bins=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 60], density=True)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(hourlyRMSE, bins = [0, 1, 2, 3, 5, 8, 10, 15, 20, 30, 40, 50, 60],density=False)\n",
    "\n",
    "for rect in ax.patches:\n",
    "    height = rect.get_height()\n",
    "    ax.annotate(f'{int(height)}', xy=(rect.get_x()+rect.get_width()/2, height), \n",
    "                xytext=(0, 5), textcoords='offset points', ha='center', va='bottom')\n",
    "ax.set_xticks([0, 1, 2, 3, 5, 8, 10, 15, 20, 30, 40, 50, 60])\n",
    "ax.set_ylabel(\"Frequency\", fontsize=16)\n",
    "ax.set_xlabel(\"RMSE Bins\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date to cheek forecasted predictions vs actual values on that date\n",
    "# dateDesired = \"2021-01-30T07:00:00.000000000\"   # good\n",
    "dateDesired = \"2021-01-26T02:00:00.000000000\"   # bad\n",
    "index = -1\n",
    "for i in range(len(dates)):\n",
    "    if dateDesired == str(dates[i]):\n",
    "        index = i\n",
    "        break\n",
    "if index == -1:\n",
    "    print(\"Could not find date!\")\n",
    "rmseValue = np.sqrt(mean_squared_error(y_test_inv[index], y_pred_inv[index]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(range(1, 25)), y_test_inv[index], label=\"Actual\")\n",
    "ax.plot(list(range(1, 25)), y_pred_inv[index], label=\"Prediction\", color=\"red\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Hours in Advance\", fontsize=14)\n",
    "ax.set_ylabel(\"Total Influent Flow\", fontsize=14)\n",
    "fig.suptitle(\"Results for \" + dateDesired[:10] + \" at \" + dateDesired[11:16], fontsize=18)\n",
    "ax.set_title(\"RMSE=\" + str(round(rmseValue, 4)), fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18d1565e3dd2a1a1180dd629712b39ff168054eb513fda549cd851c01d6423bb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
