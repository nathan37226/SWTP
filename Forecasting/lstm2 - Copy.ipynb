{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roughly following guide in:\n",
    "###### https://pangkh98.medium.com/multi-step-multivariate-time-series-forecasting-using-lstm-92c6d22cd9c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = [\"Springfield Plateau Aquifer Depth to Water Level (ft)\", \"Fire 120 Hour Rainfall Aggregate\", \"SWTP Total Influent Flow\"]\n",
    "dataset = pd.read_csv(\"Imputed Data.csv\", usecols=features)\n",
    "dataset = dataset[[\"Fire 120 Hour Rainfall Aggregate\", \"Springfield Plateau Aquifer Depth to Water Level (ft)\",\n",
    "                    \"SWTP Total Influent Flow\"]]        # reordering to match, y (variable to predict) MUST BE LAST FEATURE\n",
    "values = dataset.values\n",
    "\n",
    "# linear transformation of each feature from [min, max] to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (44173, 60, 2)\n",
      "y.shape (44173, 30)\n",
      "\n",
      "train_X.shape (35040, 60, 2)\n",
      "train_y.shape (35040, 30)\n",
      "test_X.shape (9133, 60, 2)\n",
      "test_y.shape (9133, 30)\n"
     ]
    }
   ],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "    # gather input and output parts of the pattern\n",
    "    seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# choose a number of time steps \n",
    "n_steps_in = 60\n",
    "n_steps_out = 24\n",
    "\n",
    "# covert into input/output\n",
    "X, y = split_sequences(scaled, n_steps_in, n_steps_out)\n",
    "print (\"X.shape\" , X.shape)                             # [rows, time lags backward, features]\n",
    "print (\"y.shape\" , y.shape)                             # [rows, future time values]\n",
    "\n",
    "# splitting into training and testing\n",
    "split_point = 4 * 365 * 24                              # first four years\n",
    "train_X , train_y = X[:split_point, :] , y[:split_point, :]\n",
    "test_X , test_y = X[split_point:, :] , y[split_point:, :]\n",
    "print(\"\\ntrain_X.shape\", train_X.shape)\n",
    "print(\"train_y.shape\", train_y.shape)\n",
    "print(\"test_X.shape\", test_X.shape)\n",
    "print(\"test_y.shape\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation\n",
    "\n",
    "# building model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(n_steps_in, len(features)-1)))    # the -1 is to remove target variable\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss ='mae', optimizer ='adam', metrics = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 20s 679ms/step - loss: 0.1418 - mse: 0.0372 - val_loss: 0.1205 - val_mse: 0.0276\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 16s 663ms/step - loss: 0.1311 - mse: 0.0337 - val_loss: 0.1171 - val_mse: 0.0329\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 16s 658ms/step - loss: 0.1070 - mse: 0.0245 - val_loss: 0.1033 - val_mse: 0.0242\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 16s 652ms/step - loss: 0.1075 - mse: 0.0240 - val_loss: 0.0988 - val_mse: 0.0231\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 16s 652ms/step - loss: 0.0989 - mse: 0.0201 - val_loss: 0.0950 - val_mse: 0.0172\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 18s 729ms/step - loss: 0.1006 - mse: 0.0209 - val_loss: 0.0940 - val_mse: 0.0204\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 17s 688ms/step - loss: 0.0913 - mse: 0.0171 - val_loss: 0.0881 - val_mse: 0.0154\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 17s 677ms/step - loss: 0.0904 - mse: 0.0172 - val_loss: 0.0895 - val_mse: 0.0162\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 17s 675ms/step - loss: 0.0867 - mse: 0.0156 - val_loss: 0.0849 - val_mse: 0.0147\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 17s 696ms/step - loss: 0.0822 - mse: 0.0145 - val_loss: 0.0854 - val_mse: 0.0144\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 17s 694ms/step - loss: 0.0814 - mse: 0.0142 - val_loss: 0.0841 - val_mse: 0.0143\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 17s 702ms/step - loss: 0.0796 - mse: 0.0137 - val_loss: 0.0828 - val_mse: 0.0140\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 18s 706ms/step - loss: 0.0776 - mse: 0.0133 - val_loss: 0.0821 - val_mse: 0.0138\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 17s 694ms/step - loss: 0.0763 - mse: 0.0130 - val_loss: 0.0815 - val_mse: 0.0137\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 17s 690ms/step - loss: 0.0749 - mse: 0.0127 - val_loss: 0.0808 - val_mse: 0.0135\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 17s 699ms/step - loss: 0.0737 - mse: 0.0125 - val_loss: 0.0803 - val_mse: 0.0134\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 19s 783ms/step - loss: 0.0726 - mse: 0.0122 - val_loss: 0.0796 - val_mse: 0.0133\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 19s 757ms/step - loss: 0.0717 - mse: 0.0121 - val_loss: 0.0791 - val_mse: 0.0132\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 17s 698ms/step - loss: 0.0708 - mse: 0.0119 - val_loss: 0.0784 - val_mse: 0.0131\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 17s 688ms/step - loss: 0.0702 - mse: 0.0118 - val_loss: 0.0780 - val_mse: 0.0131\n"
     ]
    }
   ],
   "source": [
    "# Fit network\n",
    "# will take a while\n",
    "history = model.fit(train_X, train_y, epochs=20, steps_per_epoch=25, \n",
    "    verbose=1, validation_data=(test_X, test_y), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_inv: (9133, 30)\n",
      "test_y_inv: (9133, 30)\n",
      "MSE 10.630680189464575\n",
      "36.83265021999999 44.198612\n",
      "36.24014786 43.74248\n",
      "37.88015705 44.65155\n",
      "40.94266323 44.92485\n",
      "42.39016823 44.684105\n",
      "46.00768234 44.468773\n",
      "46.44018364 44.274197\n",
      "46.81518364 44.08175\n",
      "46.787688059999994 44.70101\n",
      "46.58518219 44.191216\n",
      "46.497684019999994 43.930122\n",
      "43.96267318999999 44.04759\n",
      "46.520184099999994 44.307735\n",
      "44.46767715 43.84969\n",
      "44.33017448 43.823193\n",
      "44.350175629999995 43.80226\n",
      "41.4501667 43.98481\n",
      "40.33016109 42.824524\n",
      "40.33016109 43.732445\n",
      "40.33016109 43.379227\n",
      "40.33016109 43.89429\n",
      "40.33016109 43.25763\n",
      "40.33016109 42.5062\n",
      "40.33016109 42.63833\n",
      "40.33016109 42.4592\n",
      "40.33016109 42.634827\n",
      "40.33016109 42.687115\n",
      "40.33016109 43.375675\n",
      "40.33016109 42.72474\n",
      "40.33016109 43.34558\n"
     ]
    }
   ],
   "source": [
    "def invNormalize(arr, minimum, maximum):\n",
    "    return (maximum - minimum) * arr + minimum\n",
    "\n",
    "def predict(model, test_X):\n",
    "    # to be able to inverse scale predictions\n",
    "    df = pd.read_csv(\"Imputed Data.csv\", usecols=[\"SWTP Total Influent Flow\"])\n",
    "    arr = np.array(df[\"SWTP Total Influent Flow\"])\n",
    "    maximum = np.max(arr)\n",
    "    minimum = np.min(arr)\n",
    "\n",
    "    #predictions and rescaling to [min, max]\n",
    "    y_pred = model.predict(test_X)\n",
    "    y_pred_inv = np.array([invNormalize(x, minimum, maximum) for x in y_pred])\n",
    "    test_y_inv = np.array([invNormalize(x, minimum, maximum) for x in test_y])\n",
    "    print(\"y_pred_inv:\",y_pred_inv.shape)\n",
    "    print(\"test_y_inv:\",y_pred_inv.shape)\n",
    "    \n",
    "    return y_pred_inv, test_y_inv\n",
    "\n",
    "def mseForecast(y, y_pred):\n",
    "    # change so is only for a range, i.e. first 72 days of test set\n",
    "    # mse is gonna scale really badly the further out it goes\n",
    "    # msut fix! cannot calculate mse from a full year, must use a rolling window\n",
    "    # that forecasts 3 days in advance, has new next hour put into it, then has next 3 day forecast one hour after\n",
    "    totalMSE = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        mse = mean_squared_error(y[i], y_pred[i])\n",
    "        totalMSE += mean_squared_error(y[i], y_pred[i])\n",
    "    print(\"MSE:\", totalMSE / y.shape[0])\n",
    "\n",
    "y_pred_inv, test_y_inv = predict(model, test_X)\n",
    "# mseForecast(test_y_inv, y_pred_inv)\n",
    "\n",
    "print(\"MSE\", mean_squared_error(test_y_inv[0], y_pred_inv[0]))\n",
    "for y, yhat in zip(test_y_inv[0], y_pred_inv[0]):\n",
    "    print(y, yhat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18d1565e3dd2a1a1180dd629712b39ff168054eb513fda549cd851c01d6423bb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
