{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def makeNullRects(dates, y):\n",
    "    '''This function returns a list of matplotlib.patches.Rectangles where\n",
    "    np.nan values are present in the y array. If values are consecutive,\n",
    "    the rectangles will widen as needed.\n",
    "    Note that this function is made for a figure with an x-axis of dates\n",
    "    Input:\n",
    "        dates: x axis date time values\n",
    "        y: y axis range values as np.array, contains np.nan values\n",
    "\n",
    "    Returns:\n",
    "        list of matplotlib.patches.Rectangles located where\n",
    "        y has np.nan values.\n",
    "\n",
    "    Rectangle Parameters in function:\n",
    "        opacityCoeff: how solid rectangles appear\n",
    "        longRectColor: the color of the rectangles with >=7 width\n",
    "        shortRectColor: the color of the rectanges with <7 width\n",
    "    '''\n",
    "    # setting up rectangle parameters\n",
    "    opacityCoeff = 0.5\n",
    "    longRectColor = \"red\"\n",
    "    shortRectColor = \"magenta\"\n",
    "\n",
    "    # prep work for creating rectangles for nan values\n",
    "    index = 0\n",
    "    yMax = np.nanmax(y)\n",
    "    yMin = np.nanmin(y)\n",
    "    rectHeight = yMax - yMin\n",
    "    yRectCoor = yMin\n",
    "    allRects = []   # this is what will be returned\n",
    "\n",
    "    # creating rectangle patches\n",
    "    while index < len(y):\n",
    "\n",
    "        # if nan exists, then need to create a rectangle patch\n",
    "        if np.isnan(y[index]):\n",
    "            xRectCoorIndex = index - 1\n",
    "\n",
    "            # condition for if first y value is nan\n",
    "            if index == 0:\n",
    "                xRectCoorIndex += 1\n",
    "            \n",
    "            # condition for if last y value is nan, assumes y is not len 2\n",
    "            elif index + 1 == len(y):\n",
    "                xRectCoor = mdates.date2num(dates[xRectCoorIndex])\n",
    "                coords = (xRectCoor, yRectCoor)\n",
    "                width = mdates.date2num(dates[xRectCoorIndex + 1]) - mdates.date2num(dates[xRectCoorIndex])\n",
    "                allRects.append(mpatches.Rectangle(coords, width, rectHeight, color=shortRectColor, alpha=opacityCoeff))\n",
    "                break\n",
    "                \n",
    "            # all other cases\n",
    "            xRectCoor = mdates.date2num(dates[xRectCoorIndex])\n",
    "\n",
    "            # checking finding how long the rectangle needs to be--how many consecutive null values\n",
    "            index += 1\n",
    "            while np.isnan(y[index]):\n",
    "                index += 1\n",
    "            rightEdgeIndex = mdates.date2num(dates[index])\n",
    "\n",
    "            # making rectangle\n",
    "            coords = (xRectCoor, yRectCoor)\n",
    "            width = rightEdgeIndex - xRectCoor\n",
    "            color = shortRectColor\n",
    "            if index - xRectCoorIndex > 5:\n",
    "                color = longRectColor\n",
    "            allRects.append(mpatches.Rectangle(coords, width, rectHeight, color=color, alpha=opacityCoeff))\n",
    "\n",
    "        else:\n",
    "            index += 1\n",
    "\n",
    "    return allRects\n",
    "\n",
    "def visualizeMissingValues(dates, arr, fig, ax, wantToMakeNullRects = True):\n",
    "    '''This function plots an array of values with datetime x axis values onto\n",
    "    a given axis, showing patches of null values if present.\n",
    "\n",
    "    Input:\n",
    "        dates: a numpy array of datetime objs that are the x-axis for the array with missing data to plot\n",
    "        arr: a numpy array that has missing data\n",
    "        fig: a matplotlib figure that contains the axis with the plot\n",
    "        ax: a matplotlib axis that will be plotted upon\n",
    "\n",
    "    Returns:\n",
    "        fig: edited matplotlib figure\n",
    "        ax: edited matplotlib axis\n",
    "    '''\n",
    "    ax.plot(dates, arr)\n",
    "\n",
    "    if wantToMakeNullRects:\n",
    "        rects = makeNullRects(dates, arr)\n",
    "        for rect in rects:\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    formatter = mdates.ConciseDateFormatter(ax.xaxis.get_major_locator(), formats=[\"%Y\", \"%Y-%b\", \"%b-%d\", \"%d %H:%M\", \"%d %H:%M\", \"%H:%M\"])\n",
    "    locator = mdates.AutoDateLocator()\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    return fig, ax\n",
    "\n",
    "def plotImputedData(dates, nullArr, imputedArr, ax):\n",
    "    '''This graph plots imputed data as a green dashed line on a given\n",
    "    matplotlib axis.\n",
    "\n",
    "    Input:\n",
    "        dates: a numpy array of datetime objs that are the x-axis for the array with missing data to plot\n",
    "        nullArr: a numpy array that has missing data\n",
    "        imputedArr: a numpy array that has some of the missing values imputed\n",
    "        ax: a matplotlib axis that will be plotted upon\n",
    "    \n",
    "    Returns:\n",
    "        ax: edited matplotlib axis\n",
    "    '''\n",
    "    index = 0\n",
    "    while index < len(nullArr):                                 # looping through arr since it has the null values\n",
    "        if np.isnan(nullArr[index]):\n",
    "            # getting the width of the null area\n",
    "            lenForward = 0\n",
    "            while np.isnan(nullArr[index + lenForward]):\n",
    "                lenForward += 1\n",
    "\n",
    "            # domain to plot is [index-1, index+lenforward]\n",
    "            domain = list(range(index-1, index+lenForward+1))\n",
    "            datesToPlot = [dates[i] for i in domain]\n",
    "            pointsToPlot = [imputedArr[i] for i in domain]\n",
    "            ax.plot(datesToPlot, pointsToPlot, \"g--\")       # green dashed line\n",
    "\n",
    "            # moving index forward past null gap\n",
    "            index += lenForward\n",
    "        else:\n",
    "            index += 1\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def findNulls(arr):\n",
    "    index = 0\n",
    "    pairs = []                  # formatted like [(start index, num values)]\n",
    "    while index < len(arr):\n",
    "        if np.isnan(arr[index]):\n",
    "            width = 1\n",
    "            try:\n",
    "                while np.isnan(arr[index + width]):\n",
    "                    width += 1\n",
    "            except IndexError:  # means end of array is null\n",
    "                break\n",
    "            pairs.append((index, width))\n",
    "            index += width\n",
    "        else:\n",
    "            index += 1\n",
    "\n",
    "    # for pair in pairs:\n",
    "    #     print(\"Null values starting at index: {i}. {w} total nulls\".format(i=pair[0], w=pair[1]))\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def imputeArrValues(index, arr, width):\n",
    "    '''Helper function for imputeArr, which is used inside smallGapImputation.\n",
    "    '''\n",
    "    smallGapFailed = False      # represents if there's a small enough gap but was just not able to fill it in due to missing data on either side\n",
    "    if width < 5 and index + width + 1 < len(arr):\n",
    "        # interpolate data!\n",
    "        # want 6 values before and after gap for cubic spline, but more might be better\n",
    "        # technically only 4 points are needed, but more might help impute better\n",
    "        lenForwards = 1\n",
    "        while lenForwards < 10 and not np.isnan(arr[index + width + lenForwards]):\n",
    "            lenForwards += 1\n",
    "\n",
    "        lenBackwards = 1\n",
    "        while lenBackwards < 10 and not np.isnan(arr[index - lenBackwards]):\n",
    "            lenBackwards += 1\n",
    "\n",
    "        # getting values set up for imputation\n",
    "        nullRange = list(range(index, index + width, 1))\n",
    "        totalRange = list(range(index - lenBackwards + 1, index + width + lenForwards, 1))\n",
    "        x = [x for x in totalRange if x not in nullRange]       # impution data points\n",
    "        y = [arr[i] for i in x]                                 # function values of impution data points\n",
    "        imputionRange = list(range(index, index + width, 1))\n",
    "\n",
    "        if lenForwards > 5 and lenBackwards > 5:\n",
    "            # cubic spline impution\n",
    "            cspline = CubicSpline(x, y)\n",
    "            for i in imputionRange:\n",
    "                arr[i] = cspline(i)         # replacing null values in array with interpolated values\n",
    "        \n",
    "        elif (lenForwards > 5 and lenBackwards > 2) or (lenForwards > 2 and lenBackwards > 5):\n",
    "            # cubic spline but data lies mostly on one end\n",
    "            # handles cases such as [x1, x2, x3, x4, x5, x6, nan, nan, nan, x7, x8, x9]\n",
    "            cspline = CubicSpline(x, y)\n",
    "            for i in imputionRange:\n",
    "                arr[i] = cspline(i)         # replacing null values in array with interpolated values\n",
    "        \n",
    "        elif width < 3:                     # not enough values preceeding and succeeding null gap for cubic spline, but null gap is small\n",
    "            # linear impution\n",
    "            linInterplator = interp1d(x, y)\n",
    "            for i in imputionRange:\n",
    "                arr[i] = linInterplator(i)         # replacing null values in array with interpolated values\n",
    "        else:\n",
    "            smallGapFailed = True\n",
    "\n",
    "    return arr, smallGapFailed\n",
    "\n",
    "def imputeArr(arr):\n",
    "    '''Helper function for smallGapImputation.\n",
    "    '''\n",
    "    # looping through each index in the array to find nulls\n",
    "    index = 0\n",
    "    reimputeColumn = False\n",
    "    while index < len(arr):\n",
    "        # a null has been found\n",
    "        if np.isnan(arr[index]):\n",
    "            # finding how many consecutive nulls are present\n",
    "            width = 1\n",
    "            while index + width < len(arr) and np.isnan(arr[index + width]):    #not reach the end and is still null\n",
    "                width += 1\n",
    "\n",
    "            # imputation happens with this helper function\n",
    "            arr, smallGapFailed = imputeArrValues(index, arr, width)\n",
    "            if smallGapFailed:\n",
    "                reimputeColumn = True\n",
    "\n",
    "            # move index forward past gap, continue searching and imputing\n",
    "            index += width\n",
    "\n",
    "        # no null gap, so continue searching\n",
    "        else:\n",
    "            index += 1\n",
    "\n",
    "    return arr, reimputeColumn\n",
    "\n",
    "def smallGapImputation(df):\n",
    "    '''This function takes in a dataframe that has null values present.\n",
    "    For each column, this function will attempt to fill in null gaps of size 5\n",
    "    or less with cubic spline impution or, if that's not available and the gap is < 3,\n",
    "    linear impution.\n",
    "\n",
    "    Input: pandas dataframe whose columns have null values, first column is timestamp\n",
    "    Returns: df with imputed data\n",
    "    '''\n",
    "    for col in df.columns[1:]:\n",
    "        # getting an array from the dataframe\n",
    "        arr = np.array(df[col])\n",
    "\n",
    "        # to run through a column multiple times if necessary\n",
    "        count = 0\n",
    "        while count < 5:\n",
    "            arr, reimputeColumn = imputeArr(arr)\n",
    "            if reimputeColumn:\n",
    "                count += 1\n",
    "                # print(\"Reimputing {col}\".format(col=col))\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # replacing arr in df with arr with interpolated values\n",
    "        df[col] = arr\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def imputeSmallGaps():\n",
    "\n",
    "    # get original combined data with all null values\n",
    "    df = pd.read_csv(\"Joined Influent and Rainfall and Weather and Groundwater and Creek Gauge.csv\", parse_dates=[\"DateTime\"])\n",
    "    df[\"SWTP Total Influent Flow\"] = np.array([np.nan if x < 3.7 else x for x in df[\"SWTP Total Influent Flow\"]])\n",
    "\n",
    "    # imputing all small gaps with cubic splines and linear lines, gaps of size < 5\n",
    "    df = smallGapImputation(df)\n",
    "\n",
    "    # adding year, month, day, and hour columns\n",
    "    df[\"Year\"] = df[\"DateTime\"].dt.year\n",
    "    df[\"Month\"] = df[\"DateTime\"].dt.month\n",
    "    df[\"Week Day\"] = df[\"DateTime\"].dt.dayofweek\n",
    "    df[\"Hour\"] = df[\"DateTime\"].dt.hour\n",
    "    df[\"Week\"] = df[\"DateTime\"].dt.week\n",
    "\n",
    "    # saving imputed data\n",
    "    df.to_csv(\"Small Gap Imputed Data.csv\", index=False)\n",
    "\n",
    "imputeSmallGaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "def createIndicies(index, gapSize):\n",
    "    indicies = []\n",
    "    if gapSize % 2 != 0:\n",
    "        maxVal = int(gapSize/2) + index\n",
    "        minVal = int(gapSize/2) * -1 + index\n",
    "        indicies = [i for i in range(minVal, maxVal + 1)]\n",
    "    else:\n",
    "        maxVal = int(gapSize/2) + index\n",
    "        minVal = int(gapSize/2) * -1 + index + 1\n",
    "        indicies = [i for i in range(minVal, maxVal + 1)]\n",
    "    return indicies\n",
    "\n",
    "def testSmallSpot(arr, index, length):\n",
    "    if len(arr) - index > 25 and index > 25:    # not in last 25 or in first 25 indicies\n",
    "        # tests if 5 vals before and after index are null\n",
    "        # also if index is null\n",
    "        for i in range(length):\n",
    "            if np.isnan(arr[index + i]):\n",
    "                return False          \n",
    "            if np.isnan(arr[index - i]):\n",
    "                return False\n",
    "        return True                         # only if all are not null will this be hit\n",
    "    return False\n",
    "\n",
    "def testSmallGap(feature, count = 5, smallGapsPerTest = 30):\n",
    "    # getting data\n",
    "    df = pd.read_csv(\"Joined Influent and Rainfall and Weather and Groundwater and Creek Gauge.csv\", \n",
    "        usecols = [\"DateTime\", feature])\n",
    "    arr = np.array(df[feature])\n",
    "\n",
    "    # to remove sus values in a particular feature\n",
    "    if feature == \"SWTP Total Influent Flow\":\n",
    "        arr = np.array([np.nan if x < 3.7 else x for x in df[\"SWTP Total Influent Flow\"]])\n",
    "    nullArr = deepcopy(arr)                     # will be adding null values to here for validation\n",
    "\n",
    "    # starting validation\n",
    "    totalR = 0\n",
    "    breakCount = 0                              # in case not able to get as many desired spots\n",
    "    for i in range(count):                      # average of how many validation tests\n",
    "\n",
    "        spots = []                              # append all initial indicies to be turned null here\n",
    "        validationIndicies = []                 # append all indicies forced to null here\n",
    "        \n",
    "        # getting the spots to make null\n",
    "        while len(spots) < smallGapsPerTest:\n",
    "            randIndex = np.random.randint(0, len(arr))\n",
    "\n",
    "            # testing if the randomly generated index is a valid spot\n",
    "            if testSmallSpot(nullArr, randIndex, 7):\n",
    "                spots.append(randIndex)\n",
    "                nullGapWidth = np.random.randint(1, 5) # either 1, 2, 3, or 4\n",
    "\n",
    "                # making a null gap where data was previously\n",
    "                indiciesToTurnNull = createIndicies(randIndex, nullGapWidth)\n",
    "                for i in indiciesToTurnNull:\n",
    "                    nullArr[i] = np.nan\n",
    "                    validationIndicies.append(i)\n",
    "\n",
    "            # in case while loop is infinite\n",
    "            if breakCount > 5000000:             # just some large number\n",
    "                raise NotImplementedError(\"Failed to create all small null gaps\")\n",
    "        \n",
    "            breakCount += 1\n",
    "        \n",
    "        # inputing new array with created null values\n",
    "        df[feature] = nullArr\n",
    "\n",
    "        # imputing and getting r2 values\n",
    "        df = smallGapImputation(df)\n",
    "        imputedArr = df[feature]\n",
    "\n",
    "        prevValues = [arr[i] for i in validationIndicies]\n",
    "        imputedValues = [imputedArr[i] for i in validationIndicies]\n",
    "        totalR += r2_score(prevValues, imputedValues)\n",
    "    # print(\"Avg r^2 for {col} is: \\n{val}\".format(col = feature, val = totalR / count))\n",
    "\n",
    "    return totalR / count\n",
    "\n",
    "def performSmallGapValidation(featDf):\n",
    "    avgR2Vals = []\n",
    "    allFeatures = np.array(featDf[\"Feature\"])\n",
    "    for feature in allFeatures:\n",
    "    # for feature in [\"Blackman 96 Hour Rainfall Aggregate\", \"Blackman 120 Hour Rainfall Aggregate\"]:\n",
    "        print(feature)\n",
    "        avgR2Vals.append(testSmallGap(feature, 10, 100))       # r2 is avg of 15 tests, 25 small null gaps created per test\n",
    "    print(avgR2Vals)\n",
    "    # featDf[\"Avg R2\"] = avgR2Vals\n",
    "    # featDf.to_csv(\"Validated Features.csv\", index=False)\n",
    "\n",
    "    return featDf\n",
    "\n",
    "# featDf = pd.read_csv(\"Features.csv\")\n",
    "# featDf = performSmallGapValidation(featDf)\n",
    "# print(featDf)\n",
    "\n",
    "# df = pd.read_csv(\"Validated Features.csv\")\n",
    "df = pd.read_csv(\"Filtered Validated Features.csv\")\n",
    "df.plot.bar(x=\"Feature\", y=\"Avg R2\", rot=37)\n",
    "# plt.bar([i for i in range(len(df[\"Feature\"]))], df[\"Avg R2\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dcor import distance_correlation\n",
    "\n",
    "def getCorrelationPerFeature(df, targetFeature):\n",
    "    targetArr = np.array(df[targetFeature])\n",
    "    targetNullLocations = np.nonzero(np.isnan(targetArr))[0]\n",
    "\n",
    "    correlationList = []\n",
    "    cols = [col for col in df.columns if col not in [\"DateTime\", targetFeature]]\n",
    "    for col in cols:\n",
    "        # gettiing column as array and null locations\n",
    "        arr = np.array(df[col])\n",
    "        arrNullLocations = np.nonzero(np.isnan(arr))[0]\n",
    "        allNullLocations = np.unique(np.append(targetNullLocations, arrNullLocations))\n",
    "\n",
    "        # removing null indicies\n",
    "        currentTargetArr = np.delete(targetArr, allNullLocations)\n",
    "        arr = np.delete(arr, allNullLocations)\n",
    "\n",
    "        # computing \n",
    "        correlationValue = distance_correlation(currentTargetArr, arr)\n",
    "        correlationList.append((col, correlationValue))\n",
    "\n",
    "    correlationList.sort(key=lambda a: a[1])\n",
    "    correlationList = correlationList[::-1]\n",
    "    # corrDf = pd.DataFrame(np.array(correlationList), columns = [\"Feature\", \"Correlation with Target\"])\n",
    "    # print(corrDf)\n",
    "    \n",
    "    return correlationList\n",
    "\n",
    "# targetFeature = \"Ozark Aquifer Depth to Water Level (ft)\"\n",
    "targetFeature = \"Springfield Plateau Aquifer Depth to Water Level (ft)\"\n",
    "# df = pd.read_csv(\"Small Gap Imputed Data.csv\")\n",
    "df = pd.read_csv(\"Imputed Data.csv\")\n",
    "correlationList = getCorrelationPerFeature(df, targetFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ozarkCorrelationList = [('Springfield Plateau Aquifer Depth to Water Level (ft)', 0.6307472041607479), ('Week', 0.5765419244542733), ('Month', 0.5726279226642098), ('James Gauge Height (ft)', 0.5636879927117522), ('SWTP Total Influent Flow', 0.533093275904417), ('SWTP Plant 2 Influent Flow', 0.5205061617966512), ('Wilsons Gauge Height (ft)', 0.43951761698951675), ('SWTP Plant 1 Influent Flow', 0.3815965878440867), ('Sequiota 168 Hour Rainfall Aggregate', 0.3790800777831508), ('Sequiota 144 Hour Rainfall Aggregate', 0.35859381995089634), ('Sequiota 120 Hour Rainfall Aggregate', 0.3361124951332317), ('Year', 0.33475684589322774), ('Sequiota 96 Hour Rainfall Aggregate', 0.30806467669381055), ('Republic 168 Hour Rainfall Aggregate', 0.2985548939998324), ('AT&T 168 Hour Rainfall Aggregate', 0.29750850751625374), ('Hiland 168 Hour Rainfall Aggregate', 0.29675139217766533), ('Field 168 Hour Rainfall Aggregate', 0.2924034951313501), ('Willard 168 Hour Rainfall Aggregate', 0.29100906059925974), ('NW 168 Hour Rainfall Aggregate', 0.2855386912527847), ('Pittman 168 Hour Rainfall Aggregate', 0.2831864693005713), ('Hiland 144 Hour Rainfall Aggregate', 0.2823723855497944), ('Westport 168 Hour Rainfall Aggregate', 0.2823710115408092), ('Republic 144 Hour Rainfall Aggregate', 0.28043329631822683), ('AT&T 144 Hour Rainfall Aggregate', 0.2795171504344931), ('Waste 168 Hour Rainfall Aggregate', 0.27939688488900466), ('Pleasant 168 Hour Rainfall Aggregate', 0.2785139833307677), ('Weller 168 Hour Rainfall Aggregate', 0.27460603981370146), ('Field 144 Hour Rainfall Aggregate', 0.27458970133859273), ('Willard 144 Hour Rainfall Aggregate', 0.27445281575912894), ('Millwood 168 Hour Rainfall Aggregate', 0.2744424049919476), ('Sequiota 72 Hour Rainfall Aggregate', 0.2721167731721901), ('Rutledge 168 Hour Rainfall Aggregate', 0.2707097493453225), ('Fire 168 Hour Rainfall Aggregate', 0.2702133951630731), ('Sherwood 168 Hour Rainfall Aggregate', 0.26970477387268893), ('NW 144 Hour Rainfall Aggregate', 0.26932598698918603), ('Strafford 168 Hour Rainfall Aggregate', 0.26896867391737117), ('Disney 168 Hour Rainfall Aggregate', 0.2686604900200778), ('James 168 Hour Rainfall Aggregate', 0.26831648686722814), ('Bingham 168 Hour Rainfall Aggregate', 0.26803556971653875), ('Hiland 120 Hour Rainfall Aggregate', 0.2662906398387919), ('Pittman 144 Hour Rainfall Aggregate', 0.26579546912939356), ('Westport 144 Hour Rainfall Aggregate', 0.2653438267516973), ('Total 168 Hour Rainfall Aggregate', 0.2651211732477124), ('Willard_Intermediate 168 Hour Rainfall Aggregate', 0.2646803359843156), ('Sunshine 168 Hour Rainfall Aggregate', 0.26411604203806427), ('Valley 168 Hour Rainfall Aggregate', 0.2640368782184995), ('Pleasant 144 Hour Rainfall Aggregate', 0.2628851990562218), ('Le 168 Hour Rainfall Aggregate', 0.2626605734648382), ('Waste 144 Hour Rainfall Aggregate', 0.2626302529722998), ('Jefferies 168 Hour Rainfall Aggregate', 0.26186429498121505), ('Republic 120 Hour Rainfall Aggregate', 0.2601934265389541), ('AT&T 120 Hour Rainfall Aggregate', 0.26014802067271886), ('Roundtree 168 Hour Rainfall Aggregate', 0.2599020729344486), ('Millwood 144 Hour Rainfall Aggregate', 0.2580556435308486), ('Weller 144 Hour Rainfall Aggregate', 0.25783907998665784), ('Willard 120 Hour Rainfall Aggregate', 0.25663979900923933), ('Rutledge 144 Hour Rainfall Aggregate', 0.25599928879469974), ('Field 120 Hour Rainfall Aggregate', 0.2553522837563216), ('Strafford 144 Hour Rainfall Aggregate', 0.25500714120086543), ('James 144 Hour Rainfall Aggregate', 0.2541510307111001), ('Fire 144 Hour Rainfall Aggregate', 0.25404192724171476), ('Sherwood 144 Hour Rainfall Aggregate', 0.2539436667284397), \n",
    "('Disney 144 Hour Rainfall Aggregate', 0.2530527935941957), ('Bingham 144 Hour Rainfall Aggregate', 0.25210047154875603), ('NW 120 Hour Rainfall Aggregate', 0.25176045049815754), ('Total 144 Hour Rainfall Aggregate', 0.2517075864653168), ('Valley 144 Hour Rainfall Aggregate', 0.24958346865522912), ('Willard_Intermediate 144 Hour Rainfall Aggregate', 0.2490556283200971), ('Sunshine 144 Hour Rainfall Aggregate', 0.24852355557803882), ('Le 144 Hour Rainfall Aggregate', 0.24810669887320116), ('Pittman 120 Hour Rainfall Aggregate', 0.24749707982179972), ('Westport 120 Hour Rainfall Aggregate', 0.24700697344444747), ('Jefferies 144 Hour Rainfall Aggregate', 0.24665109623495626), ('Hiland 96 Hour Rainfall Aggregate', 0.24637857176725605), ('Pleasant 120 Hour Rainfall Aggregate', 0.24621414284580512), ('Waste 120 Hour Rainfall Aggregate', 0.2448116890440284), ('Roundtree 144 Hour Rainfall Aggregate', 0.24385020938943144), ('Cherokee 168 Hour Rainfall Aggregate', 0.24153369976082234), ('Shady 168 Hour Rainfall Aggregate', 0.24067834451030065), ('Weller 120 Hour Rainfall Aggregate', 0.2403943416513641), ('Rutledge 120 Hour Rainfall Aggregate', 0.24035668519467035), \n",
    "('Millwood 120 Hour Rainfall Aggregate', 0.239524347840239), ('Strafford 120 Hour Rainfall Aggregate', 0.2390755449468274), ('James 120 Hour Rainfall Aggregate', 0.2375659021974559), ('Sherwood 120 Hour Rainfall Aggregate', 0.23720134611318294), ('Fire 120 Hour Rainfall Aggregate', 0.23660288180650696), ('Airport 168 Hour Rainfall Aggregate', 0.23638541268319654), ('AT&T 96 Hour Rainfall Aggregate', 0.23630281835000333), ('Total 120 Hour Rainfall Aggregate', 0.2362648049132383), ('Republic 96 Hour Rainfall Aggregate', 0.2361654773917245), ('Disney 120 Hour Rainfall Aggregate', 0.23612157117533117), ('Bingham 120 Hour Rainfall Aggregate', 0.23532812910093917), ('Willard 96 Hour Rainfall Aggregate', 0.23489417683946853), ('Valley 120 Hour Rainfall Aggregate', 0.2343995447840297), ('Le 120 Hour Rainfall Aggregate', 0.23261859952637387), ('Field 96 Hour Rainfall Aggregate', 0.23243894817469085), ('Willard_Intermediate 120 Hour Rainfall Aggregate', 0.23234485570461447), ('Sunshine 120 Hour Rainfall Aggregate', 0.23231825501152442), ('NW 96 Hour Rainfall Aggregate', 0.23099448165634265), ('English 168 Hour Rainfall Aggregate', 0.23014656557358623), ('Jefferies 120 Hour Rainfall Aggregate', 0.22987353316879236), ('Cherokee 144 Hour Rainfall Aggregate', 0.2270747669766974), ('Pleasant 96 Hour Rainfall Aggregate', 0.22659688376348727), ('Shady 144 Hour Rainfall Aggregate', 0.22651379330817617), ('Roundtree 120 Hour Rainfall Aggregate', 0.22635119554380428), ('Airport 144 Hour Rainfall Aggregate', 0.2250796367732096), ('Westport 96 Hour Rainfall Aggregate', 0.22483879809254997), ('Pittman 96 Hour Rainfall Aggregate', 0.22479551237034942), ('Waste 96 Hour Rainfall Aggregate', 0.22393427553415146), ('SWTP Plant 1 Gravity Flow', 0.22281688798394458), ('English 144 Hour Rainfall Aggregate', 0.22246424915152896), ('Rutledge 96 Hour Rainfall Aggregate', 0.22098227058024936), ('Hiland 72 Hour Rainfall Aggregate', 0.22007452895313404), ('Weller 96 Hour Rainfall Aggregate', 0.21919715915412416), ('Strafford 96 Hour Rainfall Aggregate', 0.21886583596037126), ('Total 96 Hour Rainfall Aggregate', 0.21742536634327664), ('Millwood 96 Hour Rainfall Aggregate', 0.2167716490321167), ('Sherwood 96 Hour Rainfall Aggregate', 0.216436510730393), ('James 96 Hour Rainfall Aggregate', 0.21592691132062838), ('Disney 96 Hour Rainfall Aggregate', 0.21571571232830455), ('Valley 96 Hour Rainfall Aggregate', 0.21539586767638869), ('Fire 96 Hour Rainfall Aggregate', 0.21509328189990626), ('Bingham 96 Hour Rainfall Aggregate', 0.2146857482148008), ('Le 96 Hour Rainfall Aggregate', 0.21357119459298754), ('Willard_Intermediate 96 Hour Rainfall Aggregate', 0.21300159517117412), ('Airport 120 Hour Rainfall Aggregate', 0.21244731066372874), ('Sunshine 96 Hour Rainfall Aggregate', 0.21240589104352825), ('Shady 120 Hour Rainfall Aggregate', 0.21158403461127104), ('English 120 Hour Rainfall Aggregate', 0.21125453984434878), ('Cherokee 120 Hour Rainfall Aggregate', 0.21068024178715256), ('Jefferies 96 Hour Rainfall Aggregate', 0.2093168536252737), ('Willard 72 Hour Rainfall Aggregate', 0.20760409983942765), ('AT&T 72 Hour Rainfall Aggregate', 0.2068192589103986), ('Republic 72 Hour Rainfall Aggregate', 0.20681367066403575), ('Roundtree 96 Hour Rainfall Aggregate', 0.2058601464175766), ('Field 72 Hour Rainfall Aggregate', 0.20437893840974616), ('NW 72 Hour Rainfall Aggregate', 0.20426445546022257), ('Airport_West 168 Hour Rainfall Aggregate', 0.2021557768059795), ('Pleasant 72 Hour Rainfall Aggregate', 0.20106420218329538), ('Waste 72 Hour Rainfall Aggregate', 0.197007686208034), ('Pittman 72 Hour Rainfall Aggregate', 0.1969301250353878), ('Westport 72 Hour Rainfall Aggregate', 0.19627575740380288), ('Airport 96 Hour Rainfall Aggregate', 0.19614977110207302), ('English 96 Hour Rainfall Aggregate', 0.1956702861951137), ('Rutledge 72 Hour Rainfall Aggregate', 0.19488770677348685), ('Strafford 72 Hour Rainfall Aggregate', 0.19386122089609864), ('Shady 96 Hour Rainfall Aggregate', 0.19328283360312926), ('Total 72 Hour Rainfall Aggregate', 0.1931401943341729), ('Weller 72 Hour Rainfall Aggregate', 0.19245475043649352), ('Cherokee 96 Hour Rainfall Aggregate', 0.19137376678409568), ('Valley 72 Hour Rainfall Aggregate', 0.19054834109648455), ('Airport_West 144 Hour Rainfall Aggregate', 0.19054201029338988), ('Disney 72 Hour Rainfall Aggregate', 0.19012695788202627), ('Sherwood 72 Hour Rainfall Aggregate', 0.1898180708397562), ('Le 72 Hour Rainfall Aggregate', 0.1891027941299336), ('Millwood 72 Hour Rainfall Aggregate', 0.18907934020622533), ('Willard_Intermediate 72 Hour Rainfall Aggregate', 0.1884987405617409), ('James 72 Hour Rainfall Aggregate', 0.1883429155017829), ('Bingham 72 Hour Rainfall Aggregate', 0.18832798282147675), ('Fire 72 Hour Rainfall Aggregate', 0.18801180220100128), ('Sunshine 72 Hour Rainfall Aggregate', 0.1867367317882274), ('Jefferies 72 Hour Rainfall Aggregate', 0.1835802593835982), ('Roundtree 72 Hour Rainfall Aggregate', 0.18108560664929352), ('Airport_West 120 Hour Rainfall Aggregate', 0.17803936392471822), ('Airport 72 Hour Rainfall Aggregate', 0.1753393818083737), ('English 72 Hour Rainfall Aggregate', 0.17399142700541345), ('Shady 72 Hour Rainfall Aggregate', 0.17001773181148486), ('Cherokee 72 Hour Rainfall Aggregate', 0.16759641015713841), \n",
    "('Airport_West 96 Hour Rainfall Aggregate', 0.16317252836079457), ('SW_Peak_Flow', 0.1616236444894937), ('HourlyStationPressure', 0.15271579902818724), ('HourlyAltimeterSetting', 0.1519876727661242), ('River 168 Hour Rainfall Aggregate', 0.1498452011767934), ('HourlySeaLevelPressure', 0.14718987868136907), ('Airport_West 72 Hour Rainfall Aggregate', 0.14531536260511274), ('River 144 Hour Rainfall Aggregate', 0.13970922022769972), ('Airport_Springfield 168 Hour Rainfall Aggregate', 0.13729891459175309), ('Mark 168 Hour Rainfall Aggregate', 0.13176908834283665), ('River 120 Hour Rainfall Aggregate', 0.12935352844065576), ('Airport_Springfield 144 Hour Rainfall Aggregate', 0.12910769031762823), ('Mark 144 Hour Rainfall Aggregate', 0.12396599583614991), ('Airport_Springfield 120 Hour Rainfall Aggregate', 0.11991303578479541), ('River 96 Hour Rainfall Aggregate', 0.11694787461798342), ('Mark 120 Hour Rainfall Aggregate', 0.11531315043345582), ('Airport_Springfield 96 Hour Rainfall Aggregate', 0.10988786858045745), ('Mark 96 Hour Rainfall Aggregate', 0.105340728223974), ('River 72 Hour Rainfall Aggregate', 0.10232202884542511), ('Airport_Springfield 72 Hour Rainfall Aggregate', 0.0967608660270247), ('Mark 72 Hour Rainfall Aggregate', 0.09337510242949196), ('HourlyWetBulbTemperature', 0.09059418198330822), ('HourlyDryBulbTemperature', 0.08819100260972183), ('HourlyDewPointTemperature', 0.08777041151979946), ('Blackman 168 Hour Rainfall Aggregate', 0.08765474719145999), ('Blackman 144 Hour Rainfall Aggregate', 0.083155716834374), ('Blackman 120 Hour Rainfall Aggregate', 0.07841367288398636), ('Blackman 96 Hour Rainfall Aggregate', 0.07257553890422525), ('Sequiota Rainfall (in)', 0.06750777069010394), ('Blackman 72 Hour Rainfall Aggregate', 0.0651078109755356), ('NW Rainfall (in)', 0.05543693777927901), ('Rutledge Rainfall (in)', 0.05381348224029626), ('Hiland Rainfall (in)', 0.053696110380969886), ('James Rainfall (in)', 0.05305243382951508), ('Willard Rainfall (in)', 0.05220670432854757), ('Total Rainfall (in)', 0.05184139433221512), ('Pleasant Rainfall (in)', 0.05145325676525972), ('Republic Rainfall (in)', 0.05105062435299764), ('Valley Rainfall (in)', 0.05014734318512089), ('AT&T Rainfall (in)', 0.049703125829297604), ('Westport Rainfall (in)', 0.04892283315594852), ('Willard_Intermediate Rainfall (in)', 0.04850189246638779), ('Strafford Rainfall (in)', 0.04846012476350796), ('Le Rainfall (in)', 0.0482686296380321), ('Field Rainfall (in)', 0.04806007936708993), ('Sherwood Rainfall (in)', 0.04750710701739062), ('Millwood Rainfall (in)', 0.047282632930919485), ('Fire Rainfall (in)', 0.04700055987379547), ('Waste Rainfall (in)', 0.046909445387607156), ('Bingham Rainfall (in)', 0.04670387814383212), ('Sunshine Rainfall (in)', 0.046362475221268816), ('Weller Rainfall (in)', 0.04605963344976909), ('Pittman Rainfall (in)', 0.04502803967879383), ('Jefferies Rainfall (in)', 0.044918085631140525), ('Disney Rainfall (in)', 0.04435527020946567), ('Roundtree Rainfall (in)', 0.04332548479514482), ('Airport Rainfall (in)', 0.04248003034330316), ('Shady Rainfall (in)', 0.04166010289902156), ('Williams 72 Hour Rainfall Aggregate', 0.041383981013486656), ('Williams 96 Hour Rainfall Aggregate', 0.04098745824144807), ('Williams 168 Hour Rainfall Aggregate', 0.04091676146336944), ('Williams 144 Hour Rainfall Aggregate', 0.04091676146336944), ('Williams 120 Hour Rainfall Aggregate', 0.04091676146336944), ('English Rainfall (in)', 0.03989512268847416), ('Cherokee Rainfall (in)', 0.038858059014430485), ('HourlyRelativeHumidity', 0.037892409365553645), ('Airport_West Rainfall (in)', 0.0358809369705908), ('Airport_Springfield Rainfall (in)', 0.03318206211893972), ('River Rainfall (in)', 0.03160756583078008), ('HourlyWindSpeed', 0.02884656752918485), ('HourlyVisibility', 0.025626272725796147), ('Mark Rainfall (in)', 0.020894563511283545), ('Blackman Rainfall (in)', 0.015501730294682148), ('Williams Rainfall (in)', 0.01328631789601823), ('HourlyPressureChange', 0.012152893951929169), ('HourlyPressureTendency', 0.009456778773684667), ('Week Day', 0.006847159600733715), ('Hour', 0.0018620492588146615)]\n",
    "\n",
    "springfieldCorrelationList = [('James Gauge Height (ft)', 0.6682595437090044), ('SWTP Total Influent Flow', 0.6555463483051369), ('SWTP Plant 2 Influent Flow', 0.6361044465403347), ('Ozark Aquifer Depth to Water Level (ft)', 0.6307472041655565), ('Wilsons Gauge Height (ft)', 0.5348081187015494), ('SWTP Plant 1 Influent Flow', 0.5131380272745351), ('Sequiota 168 Hour Rainfall Aggregate', 0.49261155233603243), ('AT&T 168 Hour Rainfall Aggregate', 0.47924683180344546), ('Weller 168 Hour Rainfall Aggregate', 0.46914069961390753), ('Pleasant 168 Hour Rainfall Aggregate', 0.46836093693481723), ('Field 168 Hour Rainfall Aggregate', 0.4677687215030506), ('Fire 168 Hour Rainfall Aggregate', 0.4648271387497209), ('Le 168 Hour Rainfall Aggregate', 0.46482625262585736), ('Pittman 168 Hour Rainfall Aggregate', 0.4645865239595623), ('NW 168 Hour Rainfall Aggregate', 0.46418388798483584), ('Waste 168 Hour Rainfall Aggregate', 0.46401463740107984), ('Bingham 168 Hour Rainfall Aggregate', 0.46282093560916804), ('Jefferies 168 Hour Rainfall Aggregate', 0.4597704046209257), ('Westport 168 Hour Rainfall Aggregate', 0.4578908602354908), ('Republic 168 Hour Rainfall Aggregate', 0.45783171507823345), ('Strafford 168 Hour Rainfall Aggregate', 0.4561680567674403), ('Shady 168 Hour Rainfall Aggregate', 0.4555261201192056), ('Rutledge 168 Hour Rainfall Aggregate', 0.4549424533408891), ('Sequiota 144 Hour Rainfall Aggregate', 0.4548337679672771), ('Valley 168 Hour Rainfall Aggregate', 0.4537452680544154), ('Sunshine 168 Hour Rainfall Aggregate', 0.45250312519898506), ('Roundtree 168 Hour Rainfall Aggregate', 0.4518784630629673), ('Millwood 168 Hour Rainfall Aggregate', 0.4518611459088023), ('Disney 168 Hour Rainfall Aggregate', 0.45006996869229055), ('Willard_Intermediate 168 Hour Rainfall Aggregate', 0.44934023601414647), ('Sherwood 168 Hour Rainfall Aggregate', 0.4477758930119068), ('Willard 168 Hour Rainfall Aggregate', 0.4392164621833291), ('AT&T 144 Hour Rainfall Aggregate', 0.4379238407575416), ('Hiland 168 Hour Rainfall Aggregate', 0.43374351624349583), ('James 168 Hour Rainfall Aggregate', 0.43335490923530623), ('Weller 144 Hour Rainfall Aggregate', 0.4276919084939065), ('Field 144 Hour Rainfall Aggregate', 0.4266477822652221), ('Cherokee 168 Hour Rainfall Aggregate', 0.42646576889995086), ('Pleasant 144 Hour Rainfall Aggregate', 0.42643839452297166), ('Total 168 Hour Rainfall Aggregate', 0.4263620198177264), ('Waste 144 Hour Rainfall Aggregate', 0.42457929882349604), ('Fire 144 Hour Rainfall Aggregate', 0.4237802319777868), ('Pittman 144 Hour Rainfall Aggregate', 0.4232479959638109), ('NW 144 Hour Rainfall Aggregate', 0.42287411280768006), ('Le 144 Hour Rainfall Aggregate', 0.42284569953342266), ('Bingham 144 Hour Rainfall Aggregate', 0.4216418216072208), ('Westport 144 Hour Rainfall Aggregate', 0.4190661929329971), ('Jefferies 144 Hour Rainfall Aggregate', 0.4187868444660492), ('Rutledge 144 Hour Rainfall Aggregate', 0.4171185721060713), ('Strafford 144 Hour Rainfall Aggregate', 0.41704922393872534), ('Republic 144 Hour Rainfall Aggregate', 0.41662770356318357), ('Shady 144 Hour Rainfall Aggregate', 0.41470354016303496), ('Millwood 144 Hour Rainfall Aggregate', 0.4129726433747951), ('Valley 144 Hour Rainfall Aggregate', 0.41288065817080816), ('Sunshine 144 Hour Rainfall Aggregate', 0.4127837324431027), ('Roundtree 144 Hour Rainfall Aggregate', 0.41111209421135764), ('Disney 144 Hour Rainfall Aggregate', 0.4107772592023044), ('Willard_Intermediate 144 Hour Rainfall Aggregate', 0.4096480939999576), ('Airport 168 Hour Rainfall Aggregate', 0.40959218711762146), ('Sequiota 120 Hour Rainfall Aggregate', 0.4091605305242023), ('Sherwood 144 Hour Rainfall Aggregate', 0.4090154502890437), ('Week', 0.40632921092381735), ('Hiland 144 Hour Rainfall Aggregate', 0.4036334264595414), ('English 168 Hour Rainfall Aggregate', 0.4033708901005385), ('Willard 144 Hour Rainfall Aggregate', 0.4015487469613252), ('James 144 Hour Rainfall Aggregate', 0.3974771441413898), ('Month', 0.3968561060258641), ('Airport_West 168 Hour Rainfall Aggregate', 0.39317597518162056), ('Total 144 Hour Rainfall Aggregate', 0.3920454455796846), ('AT&T 120 Hour Rainfall Aggregate', 0.38821002985117103), ('Cherokee 144 Hour Rainfall Aggregate', 0.38697235190475276), ('Weller 120 Hour Rainfall Aggregate', 0.3777695811651127), ('Airport 144 Hour Rainfall Aggregate', 0.37678312757065285), ('Field 120 Hour Rainfall Aggregate', 0.3767742917612683), ('Waste 120 Hour Rainfall Aggregate', 0.37673313870994374), ('Pleasant 120 Hour Rainfall Aggregate', 0.3761025342332299), ('Fire 120 Hour Rainfall Aggregate', 0.37383521873783515), ('Pittman 120 Hour Rainfall Aggregate', 0.3736571987018945), ('NW 120 Hour Rainfall Aggregate', 0.3735336340619427), ('English 144 Hour Rainfall Aggregate', 0.3725638651262099), ('Le 120 Hour Rainfall Aggregate', 0.37244177223267433), ('Bingham 120 Hour Rainfall Aggregate', 0.37161253900093255), ('Westport 120 Hour Rainfall Aggregate', 0.3715929446810732), ('Rutledge 120 Hour Rainfall Aggregate', 0.37081821637666945), ('Strafford 120 Hour Rainfall Aggregate', 0.36918748312745786), ('Jefferies 120 Hour Rainfall Aggregate', 0.3690285571842881), ('Year', 0.367797611469703), ('Republic 120 Hour Rainfall Aggregate', 0.36664732728299854), ('Hiland 120 Hour Rainfall Aggregate', 0.3664518714314395), \n",
    "('Shady 120 Hour Rainfall Aggregate', 0.36541652094317023), ('Sunshine 120 Hour Rainfall Aggregate', 0.36477771773898915), ('Millwood 120 Hour Rainfall Aggregate', 0.3645824348493793), ('Valley 120 Hour Rainfall Aggregate', 0.36428518207968835), ('Disney 120 Hour Rainfall Aggregate', 0.36310969859833664), ('River 168 Hour Rainfall Aggregate', 0.36261469289321047), ('Sherwood 120 Hour Rainfall Aggregate', 0.3619826807420285), ('Willard_Intermediate 120 Hour Rainfall Aggregate', 0.36185996153310473), ('Roundtree 120 Hour Rainfall Aggregate', 0.36164645710460974), ('Airport_West 144 Hour Rainfall Aggregate', 0.35857359113807563), ('Willard 120 Hour Rainfall Aggregate', 0.3562853976311659), ('James 120 Hour Rainfall Aggregate', 0.3529357416943799), ('Sequiota 96 Hour Rainfall Aggregate', 0.35244389410195837), ('Total 120 Hour Rainfall Aggregate', 0.34914340948991257), ('Cherokee 120 Hour Rainfall Aggregate', 0.3389923448328174), ('Airport 120 Hour Rainfall Aggregate', 0.3367172103431759), ('English 120 Hour Rainfall Aggregate', 0.3338424646324984), ('River 144 Hour Rainfall Aggregate', 0.3296094403152723), ('AT&T 96 Hour Rainfall Aggregate', 0.32718954406544776), ('Hiland 96 Hour Rainfall Aggregate', 0.3189602479486714), ('Waste 96 Hour Rainfall Aggregate', 0.3177554191110962), ('Airport_West 120 Hour Rainfall Aggregate', 0.31662248873630155), ('Pleasant 96 Hour Rainfall Aggregate', 0.316184329528708), \n",
    "('Field 96 Hour Rainfall Aggregate', 0.31617771860153365), ('Weller 96 Hour Rainfall Aggregate', 0.31610568446439263), ('NW 96 Hour Rainfall Aggregate', 0.3143160136072081), ('Rutledge 96 Hour Rainfall Aggregate', 0.31396748332736335), ('Pittman 96 Hour Rainfall Aggregate', 0.3128531052204416), ('Fire 96 Hour Rainfall Aggregate', 0.3128350903882983), ('Westport 96 Hour Rainfall Aggregate', 0.3128339837491793), ('Le 96 Hour Rainfall Aggregate', 0.31085653387919177), ('Bingham 96 Hour Rainfall Aggregate', 0.3102929517669665), ('Strafford 96 Hour Rainfall Aggregate', 0.31024557112131496), ('Jefferies 96 Hour Rainfall Aggregate', 0.3088131999884786), ('Republic 96 Hour Rainfall Aggregate', 0.3075400591727575), ('Sunshine 96 Hour Rainfall Aggregate', 0.3061041048566286), ('Millwood 96 Hour Rainfall Aggregate', 0.30536170511495436), ('Disney 96 Hour Rainfall Aggregate', 0.3052465618401107), ('Shady 96 Hour Rainfall Aggregate', 0.3050697886388504), ('Valley 96 Hour Rainfall Aggregate', 0.3049518261674969), ('Willard_Intermediate 96 Hour Rainfall Aggregate', 0.3039421654322875), ('Sherwood 96 Hour Rainfall Aggregate', 0.3035103598458502), ('Roundtree 96 Hour Rainfall Aggregate', 0.30229947084786585), ('Willard 96 Hour Rainfall Aggregate', 0.30060981236386014), ('James 96 Hour Rainfall Aggregate', 0.297666205474958), ('Total 96 Hour Rainfall Aggregate', 0.2958642205203572), ('River 120 Hour Rainfall Aggregate', 0.28892368872524143), ('Airport 96 Hour Rainfall Aggregate', 0.2864535666295285), ('English 96 Hour Rainfall Aggregate', 0.2856508395647613), ('Sequiota 72 Hour Rainfall Aggregate', 0.2847959315212102), ('Cherokee 96 Hour Rainfall Aggregate', 0.28169401458996707), ('Airport_West 96 Hour Rainfall Aggregate', 0.2655000050988324), ('Hiland 72 Hour Rainfall Aggregate', 0.2601314787011252), ('AT&T 72 Hour Rainfall Aggregate', 0.25643917945082473), ('SWTP Plant 1 Gravity Flow', 0.2550182268014052), ('Waste 72 Hour Rainfall Aggregate', 0.24763822637706978), ('Rutledge 72 Hour Rainfall Aggregate', 0.246621903513602), ('Pleasant 72 Hour Rainfall Aggregate', 0.2464847279134578), ('Field 72 Hour Rainfall Aggregate', 0.2461824866806548), ('NW 72 Hour Rainfall Aggregate', 0.24504870960543781), ('Weller 72 Hour Rainfall Aggregate', 0.24358256565129532), ('Westport 72 Hour Rainfall Aggregate', 0.2434961474781645), ('Pittman 72 Hour Rainfall Aggregate', 0.2427009810764945), ('Strafford 72 Hour Rainfall Aggregate', 0.24190201436589462), ('Fire 72 Hour Rainfall Aggregate', 0.24156832975314274), ('Republic 72 Hour Rainfall Aggregate', 0.2399226523912302), ('River 96 Hour Rainfall Aggregate', 0.2393625502246285), ('Le 72 Hour Rainfall Aggregate', 0.23926236121463998), ('Bingham 72 Hour Rainfall Aggregate', 0.23918997873656403), ('Jefferies 72 Hour Rainfall Aggregate', 0.23897830203937312), ('Disney 72 Hour Rainfall Aggregate', 0.23778244125423317), ('Sunshine 72 Hour Rainfall Aggregate', 0.23760310565212936), ('Millwood 72 Hour Rainfall Aggregate', 0.23719964687027006), ('Willard_Intermediate 72 Hour Rainfall Aggregate', 0.23628665756005987), ('Valley 72 Hour Rainfall Aggregate', 0.23598947098514328), ('Willard 72 Hour Rainfall Aggregate', 0.23525614908120793), \n",
    "('Sherwood 72 Hour Rainfall Aggregate', 0.23490158254293908), ('Shady 72 Hour Rainfall Aggregate', 0.2348709530125168), ('Roundtree 72 Hour Rainfall Aggregate', 0.23426203979355367), ('Total 72 Hour Rainfall Aggregate', 0.23245146267819022), ('James 72 Hour Rainfall Aggregate', 0.23201768549528615), ('English 72 Hour Rainfall Aggregate', 0.22827096580421713), ('Airport 72 Hour Rainfall Aggregate', 0.22731273424824494), ('Cherokee 72 Hour Rainfall Aggregate', 0.21605243990177425), ('Airport_West 72 Hour Rainfall Aggregate', 0.20637837942429413), ('River 72 Hour Rainfall Aggregate', 0.18283244391708428), ('Airport_Springfield 168 Hour Rainfall Aggregate', 0.14774064817739763), ('Mark 168 Hour Rainfall Aggregate', 0.14681624941590535), ('Blackman 168 Hour Rainfall Aggregate', 0.14099505050272113), ('HourlyWetBulbTemperature', 0.1408114302337495), ('Airport_Springfield 144 Hour Rainfall Aggregate', 0.14016438167916295), ('HourlyDewPointTemperature', 0.1371754294554511), ('Mark 144 Hour Rainfall Aggregate', 0.13692074686100758), ('SW_Peak_Flow', 0.1364631920330091), ('HourlyDryBulbTemperature', 0.13612507401310667), ('Airport_Springfield 120 Hour Rainfall Aggregate', 0.13142944335464757), ('Blackman 144 Hour Rainfall Aggregate', 0.13134106371579227), ('HourlyStationPressure', 0.12745412314880214), ('HourlyAltimeterSetting', 0.12678893423774354), ('Mark 120 Hour Rainfall Aggregate', 0.12465767254218987), ('Airport_Springfield 96 Hour Rainfall Aggregate', 0.12206016689766325), ('Blackman 120 Hour Rainfall Aggregate', 0.11923932055957005), ('HourlySeaLevelPressure', 0.11282506509930637), ('Airport_Springfield 72 Hour Rainfall Aggregate', 0.11005955643417992), ('Mark 96 Hour Rainfall Aggregate', 0.10938924792118732), ('Blackman 96 Hour Rainfall Aggregate', 0.10282427629932536), ('Mark 72 Hour Rainfall Aggregate', 0.09108120414500065), ('Blackman 72 Hour Rainfall Aggregate', 0.08290786102263553), ('Sequiota Rainfall (in)', 0.05584810633704488), ('HourlyRelativeHumidity', 0.05163433537954279), ('HourlyWindSpeed', 0.05159415237561198), ('Hiland Rainfall (in)', 0.05019264265840611), ('NW Rainfall (in)', 0.043358478664041356), ('Rutledge Rainfall (in)', 0.04322496741056401), ('James Rainfall (in)', 0.04283251855051575), ('AT&T Rainfall (in)', 0.041385658532493375), ('Pleasant Rainfall (in)', 0.04110969926330502), ('English Rainfall (in)', 0.04045828530704011), ('Willard Rainfall (in)', 0.039664596091594874), ('Strafford Rainfall (in)', 0.03917619876931006), ('Total Rainfall (in)', 0.039070488663647984), ('Westport Rainfall (in)', 0.03829713464870178), ('Millwood Rainfall (in)', 0.038230716841559854), ('HourlyVisibility', 0.03807132978887514), ('Valley Rainfall (in)', 0.037924212737930625), ('Fire Rainfall (in)', 0.03755030616984465), ('Waste Rainfall (in)', 0.037487770354472504), ('Le Rainfall (in)', 0.03712608578678943), ('Sunshine Rainfall (in)', 0.03712408894501554), ('Weller Rainfall (in)', 0.037092468419905496), ('Willard_Intermediate Rainfall (in)', 0.03701233297143658), ('Bingham Rainfall (in)', 0.036902033062771344), ('Disney Rainfall (in)', 0.036885939902612845), ('Airport Rainfall (in)', 0.03671320456233719), ('Republic Rainfall (in)', 0.0366949714612916), ('Field Rainfall (in)', 0.036305832106271446), ('Jefferies Rainfall (in)', 0.036240114680229744), ('Williams 72 Hour Rainfall Aggregate', 0.0361833662449386), ('Sherwood Rainfall (in)', 0.03605416311979079), ('Shady Rainfall (in)', 0.03575687217934234), ('Pittman Rainfall (in)', 0.03569274340782442), ('Williams 96 Hour Rainfall Aggregate', 0.03564909361765943), ('Williams 168 Hour Rainfall Aggregate', 0.03557915569634159), ('Williams 144 Hour Rainfall Aggregate', 0.03557915569634159), ('Williams 120 Hour Rainfall Aggregate', 0.03557915569634159), ('Roundtree Rainfall (in)', 0.03391163050103573), ('Cherokee Rainfall (in)', 0.032726906835445435), ('River Rainfall (in)', 0.032076763035391524), ('Airport_West Rainfall (in)', 0.031153990493329013), ('Airport_Springfield Rainfall (in)', 0.030863161852477856), ('HourlyPressureChange', 0.027835771224437478), ('Week Day', 0.01794606611703306), ('Mark Rainfall (in)', 0.016258881660621793), ('HourlyPressureTendency', 0.013124291897146926), ('Blackman Rainfall (in)', 0.012761530675847892), ('Williams Rainfall (in)', 0.012036665431222568), ('Hour', 0.0026714172489968177)]\n",
    "'''\n",
    "correlationList = [('James Gauge Height (ft)', 0.6682595437090044), ('SWTP Total Influent Flow', 0.6555463483051369), ('SWTP Plant 2 Influent Flow', 0.6361044465403347), ('Ozark Aquifer Depth to Water Level (ft)', 0.6307472041655565), ('Wilsons Gauge Height (ft)', 0.5348081187015494), ('SWTP Plant 1 Influent Flow', 0.5131380272745351), ('Sequiota 168 Hour Rainfall Aggregate', 0.49261155233603243), ('AT&T 168 Hour Rainfall Aggregate', 0.47924683180344546), ('Weller 168 Hour Rainfall Aggregate', 0.46914069961390753), ('Pleasant 168 Hour Rainfall Aggregate', 0.46836093693481723), ('Field 168 Hour Rainfall Aggregate', 0.4677687215030506), ('Fire 168 Hour Rainfall Aggregate', 0.4648271387497209), ('Le 168 Hour Rainfall Aggregate', 0.46482625262585736), ('Pittman 168 Hour Rainfall Aggregate', 0.4645865239595623), ('NW 168 Hour Rainfall Aggregate', 0.46418388798483584), ('Waste 168 Hour Rainfall Aggregate', 0.46401463740107984), ('Bingham 168 Hour Rainfall Aggregate', 0.46282093560916804), ('Jefferies 168 Hour Rainfall Aggregate', 0.4597704046209257), ('Westport 168 Hour Rainfall Aggregate', 0.4578908602354908), ('Republic 168 Hour Rainfall Aggregate', 0.45783171507823345), ('Strafford 168 Hour Rainfall Aggregate', 0.4561680567674403), ('Shady 168 Hour Rainfall Aggregate', 0.4555261201192056), ('Rutledge 168 Hour Rainfall Aggregate', 0.4549424533408891), ('Sequiota 144 Hour Rainfall Aggregate', 0.4548337679672771), ('Valley 168 Hour Rainfall Aggregate', 0.4537452680544154), ('Sunshine 168 Hour Rainfall Aggregate', 0.45250312519898506), ('Roundtree 168 Hour Rainfall Aggregate', 0.4518784630629673), ('Millwood 168 Hour Rainfall Aggregate', 0.4518611459088023), ('Disney 168 Hour Rainfall Aggregate', 0.45006996869229055), ('Willard_Intermediate 168 Hour Rainfall Aggregate', 0.44934023601414647), ('Sherwood 168 Hour Rainfall Aggregate', 0.4477758930119068), ('Willard 168 Hour Rainfall Aggregate', 0.4392164621833291), ('AT&T 144 Hour Rainfall Aggregate', 0.4379238407575416), ('Hiland 168 Hour Rainfall Aggregate', 0.43374351624349583), ('James 168 Hour Rainfall Aggregate', 0.43335490923530623), ('Weller 144 Hour Rainfall Aggregate', 0.4276919084939065), ('Field 144 Hour Rainfall Aggregate', 0.4266477822652221), ('Cherokee 168 Hour Rainfall Aggregate', 0.42646576889995086), ('Pleasant 144 Hour Rainfall Aggregate', 0.42643839452297166), ('Total 168 Hour Rainfall Aggregate', 0.4263620198177264), ('Waste 144 Hour Rainfall Aggregate', 0.42457929882349604), ('Fire 144 Hour Rainfall Aggregate', 0.4237802319777868), ('Pittman 144 Hour Rainfall Aggregate', 0.4232479959638109), ('NW 144 Hour Rainfall Aggregate', 0.42287411280768006), ('Le 144 Hour Rainfall Aggregate', 0.42284569953342266), ('Bingham 144 Hour Rainfall Aggregate', 0.4216418216072208), ('Westport 144 Hour Rainfall Aggregate', 0.4190661929329971), ('Jefferies 144 Hour Rainfall Aggregate', 0.4187868444660492), ('Rutledge 144 Hour Rainfall Aggregate', 0.4171185721060713), ('Strafford 144 Hour Rainfall Aggregate', 0.41704922393872534), ('Republic 144 Hour Rainfall Aggregate', 0.41662770356318357), ('Shady 144 Hour Rainfall Aggregate', 0.41470354016303496), ('Millwood 144 Hour Rainfall Aggregate', 0.4129726433747951), ('Valley 144 Hour Rainfall Aggregate', 0.41288065817080816), ('Sunshine 144 Hour Rainfall Aggregate', 0.4127837324431027), ('Roundtree 144 Hour Rainfall Aggregate', 0.41111209421135764), ('Disney 144 Hour Rainfall Aggregate', 0.4107772592023044), ('Willard_Intermediate 144 Hour Rainfall Aggregate', 0.4096480939999576), ('Airport 168 Hour Rainfall Aggregate', 0.40959218711762146), ('Sequiota 120 Hour Rainfall Aggregate', 0.4091605305242023), ('Sherwood 144 Hour Rainfall Aggregate', 0.4090154502890437), ('Week', 0.40632921092381735), ('Hiland 144 Hour Rainfall Aggregate', 0.4036334264595414), ('English 168 Hour Rainfall Aggregate', 0.4033708901005385), ('Willard 144 Hour Rainfall Aggregate', 0.4015487469613252), ('James 144 Hour Rainfall Aggregate', 0.3974771441413898), ('Month', 0.3968561060258641), ('Airport_West 168 Hour Rainfall Aggregate', 0.39317597518162056), ('Total 144 Hour Rainfall Aggregate', 0.3920454455796846), ('AT&T 120 Hour Rainfall Aggregate', 0.38821002985117103), ('Cherokee 144 Hour Rainfall Aggregate', 0.38697235190475276), ('Weller 120 Hour Rainfall Aggregate', 0.3777695811651127), ('Airport 144 Hour Rainfall Aggregate', 0.37678312757065285), ('Field 120 Hour Rainfall Aggregate', 0.3767742917612683), ('Waste 120 Hour Rainfall Aggregate', 0.37673313870994374), ('Pleasant 120 Hour Rainfall Aggregate', 0.3761025342332299), ('Fire 120 Hour Rainfall Aggregate', 0.37383521873783515), ('Pittman 120 Hour Rainfall Aggregate', 0.3736571987018945), ('NW 120 Hour Rainfall Aggregate', 0.3735336340619427), ('English 144 Hour Rainfall Aggregate', 0.3725638651262099), ('Le 120 Hour Rainfall Aggregate', 0.37244177223267433), ('Bingham 120 Hour Rainfall Aggregate', 0.37161253900093255), ('Westport 120 Hour Rainfall Aggregate', 0.3715929446810732), ('Rutledge 120 Hour Rainfall Aggregate', 0.37081821637666945), ('Strafford 120 Hour Rainfall Aggregate', 0.36918748312745786), ('Jefferies 120 Hour Rainfall Aggregate', 0.3690285571842881), ('Year', 0.367797611469703), ('Republic 120 Hour Rainfall Aggregate', 0.36664732728299854), ('Hiland 120 Hour Rainfall Aggregate', 0.3664518714314395), \n",
    "('Shady 120 Hour Rainfall Aggregate', 0.36541652094317023), ('Sunshine 120 Hour Rainfall Aggregate', 0.36477771773898915), ('Millwood 120 Hour Rainfall Aggregate', 0.3645824348493793), ('Valley 120 Hour Rainfall Aggregate', 0.36428518207968835), ('Disney 120 Hour Rainfall Aggregate', 0.36310969859833664), ('River 168 Hour Rainfall Aggregate', 0.36261469289321047), ('Sherwood 120 Hour Rainfall Aggregate', 0.3619826807420285), ('Willard_Intermediate 120 Hour Rainfall Aggregate', 0.36185996153310473), ('Roundtree 120 Hour Rainfall Aggregate', 0.36164645710460974), ('Airport_West 144 Hour Rainfall Aggregate', 0.35857359113807563), ('Willard 120 Hour Rainfall Aggregate', 0.3562853976311659), ('James 120 Hour Rainfall Aggregate', 0.3529357416943799), ('Sequiota 96 Hour Rainfall Aggregate', 0.35244389410195837), ('Total 120 Hour Rainfall Aggregate', 0.34914340948991257), ('Cherokee 120 Hour Rainfall Aggregate', 0.3389923448328174), ('Airport 120 Hour Rainfall Aggregate', 0.3367172103431759), ('English 120 Hour Rainfall Aggregate', 0.3338424646324984), ('River 144 Hour Rainfall Aggregate', 0.3296094403152723), ('AT&T 96 Hour Rainfall Aggregate', 0.32718954406544776), ('Hiland 96 Hour Rainfall Aggregate', 0.3189602479486714), ('Waste 96 Hour Rainfall Aggregate', 0.3177554191110962), ('Airport_West 120 Hour Rainfall Aggregate', 0.31662248873630155), ('Pleasant 96 Hour Rainfall Aggregate', 0.316184329528708), \n",
    "('Field 96 Hour Rainfall Aggregate', 0.31617771860153365), ('Weller 96 Hour Rainfall Aggregate', 0.31610568446439263), ('NW 96 Hour Rainfall Aggregate', 0.3143160136072081), ('Rutledge 96 Hour Rainfall Aggregate', 0.31396748332736335), ('Pittman 96 Hour Rainfall Aggregate', 0.3128531052204416), ('Fire 96 Hour Rainfall Aggregate', 0.3128350903882983), ('Westport 96 Hour Rainfall Aggregate', 0.3128339837491793), ('Le 96 Hour Rainfall Aggregate', 0.31085653387919177), ('Bingham 96 Hour Rainfall Aggregate', 0.3102929517669665), ('Strafford 96 Hour Rainfall Aggregate', 0.31024557112131496), ('Jefferies 96 Hour Rainfall Aggregate', 0.3088131999884786), ('Republic 96 Hour Rainfall Aggregate', 0.3075400591727575), ('Sunshine 96 Hour Rainfall Aggregate', 0.3061041048566286), ('Millwood 96 Hour Rainfall Aggregate', 0.30536170511495436), ('Disney 96 Hour Rainfall Aggregate', 0.3052465618401107), ('Shady 96 Hour Rainfall Aggregate', 0.3050697886388504), ('Valley 96 Hour Rainfall Aggregate', 0.3049518261674969), ('Willard_Intermediate 96 Hour Rainfall Aggregate', 0.3039421654322875), ('Sherwood 96 Hour Rainfall Aggregate', 0.3035103598458502), ('Roundtree 96 Hour Rainfall Aggregate', 0.30229947084786585), ('Willard 96 Hour Rainfall Aggregate', 0.30060981236386014), ('James 96 Hour Rainfall Aggregate', 0.297666205474958), ('Total 96 Hour Rainfall Aggregate', 0.2958642205203572), ('River 120 Hour Rainfall Aggregate', 0.28892368872524143), ('Airport 96 Hour Rainfall Aggregate', 0.2864535666295285), ('English 96 Hour Rainfall Aggregate', 0.2856508395647613), ('Sequiota 72 Hour Rainfall Aggregate', 0.2847959315212102), ('Cherokee 96 Hour Rainfall Aggregate', 0.28169401458996707), ('Airport_West 96 Hour Rainfall Aggregate', 0.2655000050988324), ('Hiland 72 Hour Rainfall Aggregate', 0.2601314787011252), ('AT&T 72 Hour Rainfall Aggregate', 0.25643917945082473), ('SWTP Plant 1 Gravity Flow', 0.2550182268014052), ('Waste 72 Hour Rainfall Aggregate', 0.24763822637706978), ('Rutledge 72 Hour Rainfall Aggregate', 0.246621903513602), ('Pleasant 72 Hour Rainfall Aggregate', 0.2464847279134578), ('Field 72 Hour Rainfall Aggregate', 0.2461824866806548), ('NW 72 Hour Rainfall Aggregate', 0.24504870960543781), ('Weller 72 Hour Rainfall Aggregate', 0.24358256565129532), ('Westport 72 Hour Rainfall Aggregate', 0.2434961474781645), ('Pittman 72 Hour Rainfall Aggregate', 0.2427009810764945), ('Strafford 72 Hour Rainfall Aggregate', 0.24190201436589462), ('Fire 72 Hour Rainfall Aggregate', 0.24156832975314274), ('Republic 72 Hour Rainfall Aggregate', 0.2399226523912302), ('River 96 Hour Rainfall Aggregate', 0.2393625502246285), ('Le 72 Hour Rainfall Aggregate', 0.23926236121463998), ('Bingham 72 Hour Rainfall Aggregate', 0.23918997873656403), ('Jefferies 72 Hour Rainfall Aggregate', 0.23897830203937312), ('Disney 72 Hour Rainfall Aggregate', 0.23778244125423317), ('Sunshine 72 Hour Rainfall Aggregate', 0.23760310565212936), ('Millwood 72 Hour Rainfall Aggregate', 0.23719964687027006), ('Willard_Intermediate 72 Hour Rainfall Aggregate', 0.23628665756005987), ('Valley 72 Hour Rainfall Aggregate', 0.23598947098514328), ('Willard 72 Hour Rainfall Aggregate', 0.23525614908120793), \n",
    "('Sherwood 72 Hour Rainfall Aggregate', 0.23490158254293908), ('Shady 72 Hour Rainfall Aggregate', 0.2348709530125168), ('Roundtree 72 Hour Rainfall Aggregate', 0.23426203979355367), ('Total 72 Hour Rainfall Aggregate', 0.23245146267819022), ('James 72 Hour Rainfall Aggregate', 0.23201768549528615), ('English 72 Hour Rainfall Aggregate', 0.22827096580421713), ('Airport 72 Hour Rainfall Aggregate', 0.22731273424824494), ('Cherokee 72 Hour Rainfall Aggregate', 0.21605243990177425), ('Airport_West 72 Hour Rainfall Aggregate', 0.20637837942429413), ('River 72 Hour Rainfall Aggregate', 0.18283244391708428), ('Airport_Springfield 168 Hour Rainfall Aggregate', 0.14774064817739763), ('Mark 168 Hour Rainfall Aggregate', 0.14681624941590535), ('Blackman 168 Hour Rainfall Aggregate', 0.14099505050272113), ('HourlyWetBulbTemperature', 0.1408114302337495), ('Airport_Springfield 144 Hour Rainfall Aggregate', 0.14016438167916295), ('HourlyDewPointTemperature', 0.1371754294554511), ('Mark 144 Hour Rainfall Aggregate', 0.13692074686100758), ('SW_Peak_Flow', 0.1364631920330091), ('HourlyDryBulbTemperature', 0.13612507401310667), ('Airport_Springfield 120 Hour Rainfall Aggregate', 0.13142944335464757), ('Blackman 144 Hour Rainfall Aggregate', 0.13134106371579227), ('HourlyStationPressure', 0.12745412314880214), ('HourlyAltimeterSetting', 0.12678893423774354), ('Mark 120 Hour Rainfall Aggregate', 0.12465767254218987), ('Airport_Springfield 96 Hour Rainfall Aggregate', 0.12206016689766325), ('Blackman 120 Hour Rainfall Aggregate', 0.11923932055957005), ('HourlySeaLevelPressure', 0.11282506509930637), ('Airport_Springfield 72 Hour Rainfall Aggregate', 0.11005955643417992), ('Mark 96 Hour Rainfall Aggregate', 0.10938924792118732), ('Blackman 96 Hour Rainfall Aggregate', 0.10282427629932536), ('Mark 72 Hour Rainfall Aggregate', 0.09108120414500065), ('Blackman 72 Hour Rainfall Aggregate', 0.08290786102263553), ('Sequiota Rainfall (in)', 0.05584810633704488), ('HourlyRelativeHumidity', 0.05163433537954279), ('HourlyWindSpeed', 0.05159415237561198), ('Hiland Rainfall (in)', 0.05019264265840611), ('NW Rainfall (in)', 0.043358478664041356), ('Rutledge Rainfall (in)', 0.04322496741056401), ('James Rainfall (in)', 0.04283251855051575), ('AT&T Rainfall (in)', 0.041385658532493375), ('Pleasant Rainfall (in)', 0.04110969926330502), ('English Rainfall (in)', 0.04045828530704011), ('Willard Rainfall (in)', 0.039664596091594874), ('Strafford Rainfall (in)', 0.03917619876931006), ('Total Rainfall (in)', 0.039070488663647984), ('Westport Rainfall (in)', 0.03829713464870178), ('Millwood Rainfall (in)', 0.038230716841559854), ('HourlyVisibility', 0.03807132978887514), ('Valley Rainfall (in)', 0.037924212737930625), ('Fire Rainfall (in)', 0.03755030616984465), ('Waste Rainfall (in)', 0.037487770354472504), ('Le Rainfall (in)', 0.03712608578678943), ('Sunshine Rainfall (in)', 0.03712408894501554), ('Weller Rainfall (in)', 0.037092468419905496), ('Willard_Intermediate Rainfall (in)', 0.03701233297143658), ('Bingham Rainfall (in)', 0.036902033062771344), ('Disney Rainfall (in)', 0.036885939902612845), ('Airport Rainfall (in)', 0.03671320456233719), ('Republic Rainfall (in)', 0.0366949714612916), ('Field Rainfall (in)', 0.036305832106271446), ('Jefferies Rainfall (in)', 0.036240114680229744), ('Williams 72 Hour Rainfall Aggregate', 0.0361833662449386), ('Sherwood Rainfall (in)', 0.03605416311979079), ('Shady Rainfall (in)', 0.03575687217934234), ('Pittman Rainfall (in)', 0.03569274340782442), ('Williams 96 Hour Rainfall Aggregate', 0.03564909361765943), ('Williams 168 Hour Rainfall Aggregate', 0.03557915569634159), ('Williams 144 Hour Rainfall Aggregate', 0.03557915569634159), ('Williams 120 Hour Rainfall Aggregate', 0.03557915569634159), ('Roundtree Rainfall (in)', 0.03391163050103573), ('Cherokee Rainfall (in)', 0.032726906835445435), ('River Rainfall (in)', 0.032076763035391524), ('Airport_West Rainfall (in)', 0.031153990493329013), ('Airport_Springfield Rainfall (in)', 0.030863161852477856), ('HourlyPressureChange', 0.027835771224437478), ('Week Day', 0.01794606611703306), ('Mark Rainfall (in)', 0.016258881660621793), ('HourlyPressureTendency', 0.013124291897146926), ('Blackman Rainfall (in)', 0.012761530675847892), ('Williams Rainfall (in)', 0.012036665431222568), ('Hour', 0.0026714172489968177)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "%matplotlib qt\n",
    "\n",
    "def findNulls(arr):\n",
    "    index = 0\n",
    "    pairs = []                  # formatted like [(start index, num values)]\n",
    "    while index < len(arr):\n",
    "        if np.isnan(arr[index]):\n",
    "            width = 1\n",
    "            try:\n",
    "                while np.isnan(arr[index + width]):\n",
    "                    width += 1\n",
    "            except IndexError:  # means end of array is null\n",
    "                break\n",
    "            pairs.append((index, width))\n",
    "            index += width\n",
    "        else:\n",
    "            index += 1\n",
    "\n",
    "    # for pair in pairs:\n",
    "    #     print(\"Null values starting at index: {i}. {w} total nulls\".format(i=pair[0], w=pair[1]))\n",
    "    return pairs\n",
    "\n",
    "def createIndicies(index, gapSize):\n",
    "    indicies = []\n",
    "    if gapSize % 2 != 0:\n",
    "        maxVal = int(gapSize/2) + index\n",
    "        minVal = int(gapSize/2) * -1 + index\n",
    "        indicies = [i for i in range(minVal, maxVal + 1)]\n",
    "    else:\n",
    "        maxVal = int(gapSize/2) + index\n",
    "        minVal = int(gapSize/2) * -1 + index + 1\n",
    "        indicies = [i for i in range(minVal, maxVal + 1)]\n",
    "    return indicies\n",
    "\n",
    "def testLargeSpot(arr, index, length):\n",
    "    if len(arr) - index > length and index > length: \n",
    "        # tests if 5 vals before and after index are null\n",
    "        # also if index is null\n",
    "        for i in range(length):\n",
    "            if np.isnan(arr[index + i]):\n",
    "                return False          \n",
    "            if np.isnan(arr[index - i]):\n",
    "                return False\n",
    "        return True                         # only if all are not null will this be hit\n",
    "    return False\n",
    " \n",
    "def createLargeGapIndicies(arr, test_size):\n",
    "    existingLargeNullGapLengths = [x[1] for x in findNulls(arr) if x[1] > 5]\n",
    "    minGapSize = 5\n",
    "    maxGapSize = max(existingLargeNullGapLengths, default=150)\n",
    "    spots = []                              # append all initial indicies to be turned null here\n",
    "    validationIndicies = []                 # append all indicies forced to null here\n",
    "    nullArr = deepcopy(arr)                     # will be adding null values to here for validation\n",
    "\n",
    "    # getting the spots to make null\n",
    "    breakout = 0\n",
    "    totalCreatedNulls = 0\n",
    "    hasLargestGap = False\n",
    "    while totalCreatedNulls / len(arr) < test_size and breakout < 500000:\n",
    "        # randomly getting index and how large of gap to create\n",
    "        randIndex = np.random.randint(0, len(arr))\n",
    "        randGapSize = np.random.randint(minGapSize, maxGapSize)\n",
    "        if not hasLargestGap:\n",
    "            randGapSize = maxGapSize\n",
    "            hasLargestGap = True\n",
    "\n",
    "        # testing if spot is valid\n",
    "        if testLargeSpot(nullArr, randIndex, randGapSize):\n",
    "            spots.append(randIndex)\n",
    "            totalCreatedNulls += randGapSize\n",
    "            \n",
    "            # making a null gap where data was previously\n",
    "            indiciesToTurnNull = createIndicies(randIndex, randGapSize)\n",
    "            for i in indiciesToTurnNull:\n",
    "                nullArr[i] = np.nan\n",
    "                validationIndicies.append(i)\n",
    "\n",
    "        breakout += 1\n",
    "    return validationIndicies\n",
    "\n",
    "def train_test_split_largeGap(data, target, test_size = 0.1):\n",
    "    trainX, trainY = deepcopy(data), deepcopy(target)\n",
    "    testX, testY = [], []\n",
    "    validationIndicies = np.sort(np.array(createLargeGapIndicies(target, test_size)))\n",
    "    for index in validationIndicies:\n",
    "        testX.append(data[index])\n",
    "        testY.append(target[index])\n",
    "    testX, testY = np.array(testX), np.array(testY)\n",
    "    trainX = np.delete(trainX, validationIndicies, 0)\n",
    "    trainY = np.delete(trainY, validationIndicies)\n",
    "    return trainX, testX, trainY, testY, validationIndicies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02750132169140654 with 9 features, 10 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.027520025706964074 with 7 features, 10 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.027528424581983707 with 7 features, 10 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.027546466555528504 with 7 features, 10 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.027577814762204233 with 9 features, 10 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.027629094048223682 with 5 features, 10 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.02765887322868521 with 5 features, 10 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.027668715628490683 with 9 features, 10 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.02772261642370331 with 5 features, 10 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.028209361747770265 with 7 features, 7 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.028211002777877858 with 9 features, 7 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.02821141643414227 with 5 features, 7 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.028218669163207977 with 5 features, 7 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.02827759626974914 with 9 features, 7 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.028284583558 with 9 features, 7 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.02830608696366968 with 7 features, 7 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.028315415015557757 with 7 features, 7 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.028359609313419566 with 5 features, 7 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.028791983058276866 with 5 features, 5 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.028845236240271747 with 5 features, 5 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.028886426477558857 with 9 features, 5 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.02890810958275904 with 7 features, 5 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.028936278404585878 with 9 features, 5 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.028956026298589333 with 5 features, 5 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.028989477813481313 with 7 features, 5 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.02898975925040202 with 7 features, 5 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.029023307038513208 with 9 features, 5 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.029723709805403595 with 7 features, 3 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.029766435668699395 with 5 features, 3 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.02976720523218078 with 7 features, 3 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.02978315470230898 with 5 features, 3 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.02980134685476525 with 9 features, 3 max depth, 50 trees, and a scale factor of 0.1\n",
      "0.02980787001177747 with 5 features, 3 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.029817591308916452 with 7 features, 3 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.02982113885395601 with 9 features, 3 max depth, 75 trees, and a scale factor of 0.1\n",
      "0.029871520157890862 with 9 features, 3 max depth, 100 trees, and a scale factor of 0.1\n",
      "0.03099838701547271 with 9 features, 10 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.031046165350330807 with 7 features, 10 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.0310821962225472 with 7 features, 10 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.03109537394956553 with 7 features, 10 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.031195529084088597 with 9 features, 10 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.031217920051147097 with 5 features, 10 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.031322480717675946 with 5 features, 10 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.031364740698888456 with 9 features, 10 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.03144979766732068 with 5 features, 10 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03319001928518754 with 7 features, 7 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.033199971674073 with 9 features, 7 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03326009110711934 with 5 features, 7 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.03331348552085268 with 5 features, 7 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03334693300979943 with 9 features, 7 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.033368352289720495 with 7 features, 7 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03338175792766621 with 7 features, 7 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.03340123634395243 with 9 features, 7 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.03365296814187004 with 5 features, 7 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.03540858870270952 with 9 features, 5 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.035414238274513336 with 5 features, 5 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.0354587120736173 with 7 features, 5 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.035472487728359904 with 5 features, 5 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.035612937963355504 with 9 features, 5 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03564448937513353 with 7 features, 5 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.03568945971121049 with 7 features, 5 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03569912047416863 with 5 features, 5 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.03571823428738886 with 9 features, 5 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.038803479552872645 with 7 features, 3 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.038806905594599456 with 7 features, 3 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.038817998992805296 with 9 features, 3 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.03887724178958189 with 9 features, 3 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.038896752960403326 with 7 features, 3 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.03896217848284935 with 9 features, 3 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.039024283742093824 with 5 features, 3 max depth, 50 trees, and a scale factor of 0.2\n",
      "0.039061709622077646 with 5 features, 3 max depth, 100 trees, and a scale factor of 0.2\n",
      "0.039108812313484724 with 5 features, 3 max depth, 75 trees, and a scale factor of 0.2\n",
      "0.06276765894800543 with 9 features, 10 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.0629648820632233 with 7 features, 10 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.06304640395249204 with 5 features, 10 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.06306035532710415 with 7 features, 10 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.06319920766009267 with 7 features, 10 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.06359168357219887 with 9 features, 10 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.06364532291085774 with 5 features, 10 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.06392028672590082 with 9 features, 10 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.06396234448203353 with 5 features, 10 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.07406338079969772 with 7 features, 7 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.07413828923693849 with 9 features, 7 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.07438996820767217 with 7 features, 7 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.07439583260653607 with 7 features, 7 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.07460900021613376 with 9 features, 7 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.07473327872343587 with 5 features, 7 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.0750472242339006 with 9 features, 7 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.07515843192478343 with 5 features, 7 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.07643915588178328 with 5 features, 7 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.0860931040280888 with 9 features, 5 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.08626909115916381 with 7 features, 5 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.08690211915968128 with 7 features, 5 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.08713635146056688 with 9 features, 5 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.08734994784389923 with 5 features, 5 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.08735604407426166 with 7 features, 5 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.0873888177291433 with 9 features, 5 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.08756625103535681 with 5 features, 5 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.08795442442722279 with 5 features, 5 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.10646340127095044 with 9 features, 3 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.10675894925085531 with 9 features, 3 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.10685259662450691 with 9 features, 3 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.10686459162765927 with 7 features, 3 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.10700727413466275 with 7 features, 3 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.10748276261204877 with 7 features, 3 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.10879913105068001 with 5 features, 3 max depth, 50 trees, and a scale factor of 0.5\n",
      "0.10927368712256165 with 5 features, 3 max depth, 75 trees, and a scale factor of 0.5\n",
      "0.10942417535466205 with 5 features, 3 max depth, 100 trees, and a scale factor of 0.5\n",
      "0.18630056342998272 with 5 features, 10 max depth, 75 trees, and a scale factor of 1\n",
      "0.18664336537000728 with 9 features, 10 max depth, 75 trees, and a scale factor of 1\n",
      "0.18729706919401856 with 7 features, 10 max depth, 100 trees, and a scale factor of 1\n",
      "0.18739618827442703 with 7 features, 10 max depth, 75 trees, and a scale factor of 1\n",
      "0.18824654844218522 with 7 features, 10 max depth, 50 trees, and a scale factor of 1\n",
      "0.1886234589868594 with 5 features, 10 max depth, 50 trees, and a scale factor of 1\n",
      "0.18925326611942406 with 5 features, 10 max depth, 100 trees, and a scale factor of 1\n",
      "0.18939531279390662 with 9 features, 10 max depth, 100 trees, and a scale factor of 1\n",
      "0.18973776615698476 with 9 features, 10 max depth, 50 trees, and a scale factor of 1\n",
      "0.22862361299807601 with 7 features, 7 max depth, 50 trees, and a scale factor of 1\n",
      "0.2287675904866174 with 7 features, 7 max depth, 75 trees, and a scale factor of 1\n",
      "0.22891058093010588 with 7 features, 7 max depth, 100 trees, and a scale factor of 1\n",
      "0.22894018808931457 with 9 features, 7 max depth, 100 trees, and a scale factor of 1\n",
      "0.23022596884730231 with 9 features, 7 max depth, 75 trees, and a scale factor of 1\n",
      "0.23161247007524763 with 5 features, 7 max depth, 75 trees, and a scale factor of 1\n",
      "0.23211063582411726 with 9 features, 7 max depth, 50 trees, and a scale factor of 1\n",
      "0.23343500036799028 with 5 features, 7 max depth, 100 trees, and a scale factor of 1\n",
      "0.23743650629684476 with 5 features, 7 max depth, 50 trees, and a scale factor of 1\n",
      "0.2742940584034785 with 9 features, 5 max depth, 75 trees, and a scale factor of 1\n",
      "0.2748149616783137 with 7 features, 5 max depth, 50 trees, and a scale factor of 1\n",
      "0.27664296683510503 with 7 features, 5 max depth, 75 trees, and a scale factor of 1\n",
      "0.27727766483770044 with 9 features, 5 max depth, 50 trees, and a scale factor of 1\n",
      "0.2786891469122256 with 7 features, 5 max depth, 100 trees, and a scale factor of 1\n",
      "0.27950162097038583 with 9 features, 5 max depth, 100 trees, and a scale factor of 1\n",
      "0.2804647335407143 with 5 features, 5 max depth, 50 trees, and a scale factor of 1\n",
      "0.2818000024367005 with 5 features, 5 max depth, 100 trees, and a scale factor of 1\n",
      "0.2821037626772094 with 5 features, 5 max depth, 75 trees, and a scale factor of 1\n",
      "0.3545238912812761 with 9 features, 3 max depth, 50 trees, and a scale factor of 1\n",
      "0.35539810408321 with 9 features, 3 max depth, 100 trees, and a scale factor of 1\n",
      "0.3556064572009634 with 9 features, 3 max depth, 75 trees, and a scale factor of 1\n",
      "0.35675601816877145 with 7 features, 3 max depth, 100 trees, and a scale factor of 1\n",
      "0.3567682634910913 with 7 features, 3 max depth, 75 trees, and a scale factor of 1\n",
      "0.3600814804332391 with 7 features, 3 max depth, 50 trees, and a scale factor of 1\n",
      "0.36526207719576237 with 5 features, 3 max depth, 50 trees, and a scale factor of 1\n",
      "0.3670886381508738 with 5 features, 3 max depth, 75 trees, and a scale factor of 1\n",
      "0.36828376448380135 with 5 features, 3 max depth, 100 trees, and a scale factor of 1\n",
      "Best hyperparas are: 9 features, 10 depth 75 trees, and a scale factor of 0.1\n",
      "With an MSE of: 0.02750132169140654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def saveForestPredictions(originFilename, predFilename, feature):\n",
    "    # building dataframes\n",
    "    originDf = pd.read_csv(originFilename, parse_dates=[\"DateTime\"])\n",
    "    predDf = pd.read_csv(predFilename, parse_dates=[\"DateTime\"])\n",
    "\n",
    "    # getting arrays from dataframes\n",
    "    predArr = np.array(predDf[predDf.columns[-1]])\n",
    "    predDates = np.array(predDf[\"DateTime\"])\n",
    "    originArr = np.array(originDf[feature])\n",
    "    originDates = np.array(originDf[\"DateTime\"])\n",
    "\n",
    "    # copying over predicted values\n",
    "    for i in range(len(predDates)):\n",
    "        locations = np.nonzero(originDates == predDates[i])\n",
    "        originArr[locations[0]] = predArr[i]\n",
    "\n",
    "    # replacing array in df and saving to csv\n",
    "    df[feature] = originArr\n",
    "    df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "def findSharedNullValueFeatures(df, targetFeature, tol = 0.5):\n",
    "    # getting location of target nulls\n",
    "    target = np.array(df[targetFeature])\n",
    "    targetNulls = np.nonzero(np.isnan(target))[0]\n",
    "\n",
    "    # getting columns\n",
    "    columnList = [x for x in df.columns if x not in [\"DateTime\", targetFeature]]\n",
    "    badColumns = []\n",
    "    for col in columnList:\n",
    "        # getting how many null values are shared between target and each feature\n",
    "        arr = np.array(df[col])\n",
    "        arrNulls = np.nonzero(np.isnan(arr))[0]\n",
    "        sharedNullIncidiesCount = len(np.intersect1d(targetNulls, arrNulls))\n",
    "        \n",
    "        # if share tol% or more null features, then leave that feature out\n",
    "        if sharedNullIncidiesCount > tol * len(targetNulls):\n",
    "            badColumns.append(col)\n",
    "\n",
    "    return badColumns\n",
    "\n",
    "def separateDataIntoSets(target, data, dates):\n",
    "    # getting null locations from target feature array\n",
    "    targetNulls = np.nonzero(np.isnan(target))[0]\n",
    "\n",
    "    # getting data corresponding to where the target feature is null\n",
    "    testData = []\n",
    "    testDates = []\n",
    "    for i in targetNulls:\n",
    "        testData.append(data[i])\n",
    "        testDates.append(dates[i])\n",
    "    testData = np.array(testData)\n",
    "    testDates = np.array(testDates)\n",
    "\n",
    "    # deleting all indicies that are null from target and data\n",
    "    trainTarget = np.delete(target, targetNulls)\n",
    "    trainData = np.delete(data, targetNulls, 0)     # the 0 means delete a row\n",
    "\n",
    "    # finding where null values are present in the data that has a not null target corresponding to it\n",
    "    badIndicies = []\n",
    "    for col in range(len(trainData[0])):\n",
    "        for row in range(len(trainData)):\n",
    "            if np.isnan(trainData[row][col]):\n",
    "                badIndicies.append(row)\n",
    "\n",
    "    # removing those indicies so that rand forest can train\n",
    "    if len(badIndicies) > 0:\n",
    "        badIndicies = np.unique(np.array(badIndicies))\n",
    "        trainData = np.delete(trainData, badIndicies, 0)\n",
    "        trainTarget = np.delete(trainTarget, badIndicies)\n",
    "\n",
    "    # finding where null values are present in the data that has a null target corresponding to it\n",
    "    badIndicies = []\n",
    "    for col in range(len(testData[0])):\n",
    "        for row in range(len(testData)):\n",
    "            if np.isnan(testData[row][col]):\n",
    "                badIndicies.append(row)\n",
    "    \n",
    "    # removing those indicies so that rand forest can predict\n",
    "    if len(badIndicies) > 0:\n",
    "        badIndicies = np.unique(np.array(badIndicies))\n",
    "        testData = np.delete(testData, badIndicies, 0)\n",
    "        testDates = np.delete(testDates, badIndicies)\n",
    "    \n",
    "    return trainData, trainTarget, testData, testDates\n",
    "\n",
    "def scalePredictedValues(dates, fullTarget, predictedValues, predictedIndicies, scaleFactor):\n",
    "    # copying over predicted values\n",
    "    fullPredTarget = deepcopy(fullTarget)\n",
    "    validNullTarget = deepcopy(fullTarget)                 # used in linear scaling step to find where to scale\n",
    "    predDates = [dates[i] for i in predictedIndicies]\n",
    "    for i in range(len(predDates)):\n",
    "        locations = np.nonzero(dates == predDates[i])\n",
    "        fullPredTarget[locations[0]] = predictedValues[i]\n",
    "        validNullTarget[locations[0]] = np.nan\n",
    "    \n",
    "    scalingSpots = findNulls(validNullTarget)\n",
    "    for tup in scalingSpots:\n",
    "        # getting points to make trendline, using 10 points\n",
    "        points = []\n",
    "        for i in range(1, 11):                   # at tup[0], target is null, so start with i = 1\n",
    "            xBefore = tup[0] - i\n",
    "            yBefore = fullTarget[xBefore]\n",
    "            xAfter = tup[0] + tup[1] - 1 + i\n",
    "            yAfter = fullTarget[xAfter]\n",
    "\n",
    "            # condition if cannot get all 10 points desired due to other null gaps close to current gap\n",
    "            if np.isnan(yBefore) or np.isnan(yAfter):\n",
    "                break\n",
    "            \n",
    "            # appending points\n",
    "            points.append((xBefore, yBefore))\n",
    "            points.append((xAfter, yAfter))\n",
    "\n",
    "        # creating trendline from points\n",
    "        trendlineCoeffs = np.polyfit(np.array([p[0] for p in points]), np.array([p[1] for p in points]), 1)\n",
    "        trendline = np.poly1d(trendlineCoeffs)\n",
    "\n",
    "        # scaling predicted values\n",
    "        for i in range(tup[1]):\n",
    "            fullPredTarget[tup[0] + i] = trendline(tup[0] + i) + scaleFactor * (fullPredTarget[tup[0] + i] - trendline(tup[0] + i))\n",
    "\n",
    "    # slicing out scaled prediced values\n",
    "    scaledPredictedValues = [fullPredTarget[i] for i in predictedIndicies]\n",
    "\n",
    "    return scaledPredictedValues\n",
    "\n",
    "def tuneForest(df, targetFeature):\n",
    "    # getting data to use\n",
    "    target = np.array(df[targetFeature])\n",
    "    dates = np.array(df[\"DateTime\"])\n",
    "    badFeaturesToUse = findSharedNullValueFeatures(df, targetFeature)\n",
    "    badFeaturesToUse += [targetFeature, \"DateTime\"]\n",
    "    df = df.drop(columns=badFeaturesToUse)\n",
    "    data = df.to_numpy()\n",
    "\n",
    "    # splitting data up into respective datasets\n",
    "    validData, validTarget, nullData, nullDates = separateDataIntoSets(target, data, dates)\n",
    "\n",
    "    # setting up possible hyperparameter values\n",
    "    maxNumFeatures = list(range(5, int(len(df.columns)/1.75) + 1, 2))\n",
    "    maxDepths = [3, 5, 7, 10]\n",
    "    numTrees = [50, 75, 100]\n",
    "    scaleFactors = [.1, .2, .5, 1]\n",
    "    # maxNumFeatures = [9]\n",
    "    # maxDepths = [10]\n",
    "    # numTrees = [75]\n",
    "    # scaleFactors = [.1, 1]\n",
    "    \n",
    "    \n",
    "    numValidations = 3\n",
    "    avgDict = {}\n",
    "    for n in range(numValidations):\n",
    "        # splitting up known data into training and validation sets\n",
    "        XTrain, XTest, YTrain, YTest, testIndicies = train_test_split_largeGap(validData, validTarget, test_size=0.20)\n",
    "\n",
    "        # grid searching for best combination\n",
    "        combos = []\n",
    "        for numFeats in maxNumFeatures:\n",
    "            for maxDepth in maxDepths:\n",
    "                for trees in numTrees:\n",
    "                    # only previous for loops impact the random forest's performance\n",
    "                    imputer = RandomForestRegressor(n_estimators=trees, max_depth=maxDepth, max_features=numFeats)\n",
    "                    imputer.fit(XTrain, YTrain)\n",
    "                    predictedValues = imputer.predict(XTest)\n",
    "                    # print(mean_squared_error(YTest, predictedValues))   # original mse without scaling\n",
    "\n",
    "                    for scale in scaleFactors:\n",
    "                        # linear trendline scaling\n",
    "                        scaledPredictedValues = scalePredictedValues(dates, validTarget, predictedValues, testIndicies, scale)\n",
    "                        mse = mean_squared_error(YTest, scaledPredictedValues)\n",
    "                        combos.append((mse, (numFeats, maxDepth, trees, scale)))\n",
    "        \n",
    "        # adding combos info to the average dictionary\n",
    "        for tup in combos:\n",
    "            if tup[1] in avgDict.keys():\n",
    "                avgDict[tup[1]] += tup[0]\n",
    "            else:\n",
    "                avgDict[tup[1]] = tup[0]\n",
    "    \n",
    "    # getting info out of avgDict and into a list to sort\n",
    "    combos = [(tup[1]/numValidations, tup[0]) for tup in avgDict.items()]\n",
    "\n",
    "    combos.sort(key=lambda a: a[0])\n",
    "    for tup in combos:\n",
    "        print(tup[0], \"with {f} features, {d} max depth, {t} trees, and a scale factor of {s}\".format(\n",
    "            f = tup[1][0], d = tup[1][1], t = tup[1][2], s = tup[1][3]))\n",
    "\n",
    "    # creating best tree predictions\n",
    "    print(\"Best hyperparas are: {f} features, {d} depth {t} trees, and a scale factor of {s}\".format(\n",
    "        f = combos[0][1][0], d = combos[0][1][1], t = combos[0][1][2], s = combos[0][1][3]))\n",
    "    print(\"With an MSE of: {m}\".format(m = combos[0][0]))\n",
    "    imputer = RandomForestRegressor(max_features=combos[0][1][0], max_depth=combos[0][1][1], n_estimators=combos[0][1][2])\n",
    "    # imputer = RandomForestRegressor(max_features=9, max_depth=10, n_estimators=75)\n",
    "    imputer.fit(validData, validTarget)\n",
    "    imputedValues = imputer.predict(nullData)\n",
    "    imputedValues = scalePredictedValues(dates, target, imputedValues, \n",
    "        [i for i in range(len(target)) if np.isnan(target[i])], combos[0][1][3])\n",
    "\n",
    "    # saving to a dataframe\n",
    "    predData = np.array((np.array(nullDates), imputedValues)).T\n",
    "    newDf = pd.DataFrame(predData, columns=[\"DateTime\", \"Predicted Ozark Groundwater Depth (ft)\"])\n",
    "    newDf.to_csv(\"predicted forest.csv\", index=False)\n",
    "\n",
    "\n",
    "# targetFeature = \"Ozark Aquifer Depth to Water Level (ft)\"\n",
    "targetFeature = \"Springfield Plateau Aquifer Depth to Water Level (ft)\"\n",
    "# correlationList = getCorrelationPerFeature(df, targetFeature)\n",
    "topCorrelatedFeatures = [x[0] for x in correlationList[:20]] + [\"DateTime\", targetFeature]\n",
    "df = pd.read_csv(\"Small Gap Imputed Data.csv\", usecols=topCorrelatedFeatures)\n",
    "tuneForest(df, targetFeature)\n",
    "# ozark: best was 9 features, 10 max depth, 75 trees, and a scale factor of 0.1 in full grid search with mse of 0.9284514998810384\n",
    "# springfield: best was 9 features, 10 max depth, 75 trees, and a scale factor of 0.1 in full grid search with mse of 0.02750132169140654\n",
    "saveForestPredictions(\"Small Gap Imputed Data.csv\", \"predicted forest.csv\", targetFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "%matplotlib qt\n",
    "\n",
    "# feature = \"SWTP Total Influent Flow\"\n",
    "# feature = \"Ozark Aquifer Depth to Water Level (ft)\"\n",
    "feature = \"Springfield Plateau Aquifer Depth to Water Level (ft)\"\n",
    "# feature = \"James Gauge Height (ft)\"\n",
    "# feature = \"Wilsons Gauge Height (ft)\"\n",
    "# feature = \"Fire 168 Hour Rainfall Aggregate\"\n",
    "# feature = \"HourlyPressureChange\"\n",
    "\n",
    "\n",
    "# df = pd.read_csv(\"Joined Influent and Rainfall and Weather and Groundwater and Creek Gauge.csv\", parse_dates=[\"DateTime\"])\n",
    "df = pd.read_csv(\"Small Gap Imputed Data.csv\", parse_dates=[\"DateTime\"])\n",
    "# df = pd.read_csv(\"Small Gap Imputed Data Editted.csv\", parse_dates=[\"DateTime\"])\n",
    "# df[\"SWTP Total Influent Flow\"] = np.array([np.nan if x < 3.7 else x for x in df[\"SWTP Total Influent Flow\"]])\n",
    "\n",
    "\n",
    "# imputedDf = pd.read_csv(\"Small Gap Imputed Data.csv\")\n",
    "# imputedDf = pd.read_csv(\"Small Gap Imputed Data Editted.csv\")\n",
    "imputedDf = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "dates = np.array(df[\"DateTime\"])\n",
    "imputedArr = np.array(imputedDf[feature])\n",
    "nullArr = deepcopy(np.array(df[feature]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig, ax = visualizeMissingValues(dates, nullArr, fig, ax)\n",
    "ax = plotImputedData(dates, nullArr, imputedArr, ax)\n",
    "# ax.scatter(testDf[\"DateTime\"], testDf[testDf.columns[-1]], s=8, color=\"red\", marker=\"x\")\n",
    "ax.set_ylabel(feature)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18d1565e3dd2a1a1180dd629712b39ff168054eb513fda549cd851c01d6423bb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
