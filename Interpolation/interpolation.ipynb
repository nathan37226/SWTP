{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first two cells are for interpolating missing data.\n",
    "#### If you already have the data, do not run them. They take ~5-6 minutes.\n",
    "\n",
    "The first cell runs through each feature in the joined data, interpolating missing values\n",
    "when 5 or less are present sequentially.\n",
    "This interpolation is done through linear and cubic splines.\n",
    "Note that this does not remove the large gaps of null values\n",
    "\n",
    "The second cell interpolates all the large null gaps for some features, each to a different level of success.\n",
    "The list of interpolated features is named 'desiredColumns'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "df = pd.read_csv(\"Joined Influent and Rainfall and Weather and Groundwater and Creek Gauge.csv\", parse_dates=[\"DateTime\"])\n",
    "df[\"SWTP Total Influent Flow\"] = np.array([np.nan if x < 3.7 else x for x in df[\"SWTP Total Influent Flow\"]])\n",
    "\n",
    "for col in df.columns:\n",
    "    # getting an array from the dataframe\n",
    "    index = 0\n",
    "    arr = np.array(df[col])\n",
    "\n",
    "    # looping through each index in the array to find nulls\n",
    "    while index < len(arr):\n",
    "        # a null has been found\n",
    "        if np.isnan(arr[index]):\n",
    "            # getting width of null gap\n",
    "            width = 1\n",
    "            while index + width < len(arr) and np.isnan(arr[index + width]):    #not reach the end and is still null\n",
    "                width += 1\n",
    "            # print(\"Index = {i}, width = {w}\".format(i = index, w = width))\n",
    "\n",
    "            if width < 6 and index + width + 1 < len(arr):\n",
    "                # interpolate data!\n",
    "                # want next 10 values before and after if not null\n",
    "                # else however many there are available until first null, guarenteed at least 1\n",
    "                if width == 1:\n",
    "                    # linear interpolate\n",
    "                    x = [index-1] + [index+1]\n",
    "                    y = [arr[i] for i in x]\n",
    "                    linInterplator = interp1d(x, y)\n",
    "                    \n",
    "                    # adding imputed value into array\n",
    "                    arr[index] = linInterplator(index)\n",
    "                \n",
    "                elif width == 2:\n",
    "                    # linear interpolate\n",
    "                    x = [index-1] + [index+2]\n",
    "                    y = [arr[i] for i in x]\n",
    "                    linInterplator = interp1d(x, y)\n",
    "\n",
    "                    # adding imputed values into array\n",
    "                    arr[index] = linInterplator(index)\n",
    "                    arr[index+1] = linInterplator(index+1)\n",
    "\n",
    "                else:\n",
    "                    # cubic spline interpolation -- sometimes prone to unbelieveable imputed data, but generally close enough to seem right\n",
    "                    lenForwards = 0\n",
    "                    while lenForwards < 10 and not np.isnan(arr[index + width + lenForwards + 1]):\n",
    "                        lenForwards += 1\n",
    "\n",
    "                    lenBackwards = 0\n",
    "                    while lenBackwards < 10 and not np.isnan(arr[index - lenBackwards - 1]):\n",
    "                        lenBackwards += 1\n",
    "                    \n",
    "                    # getting x and y values for cubic spline and building spline\n",
    "                    nullRange = list(range(index, index + width, 1))\n",
    "                    totalRange = list(range(index - lenBackwards, index + width + lenForwards + 1, 1))\n",
    "                    x = [x for x in totalRange if x not in nullRange]\n",
    "                    y = [arr[i] for i in x]\n",
    "                    cspline = CubicSpline(x, y)\n",
    "\n",
    "                    # replacing null values in array with interpolated values\n",
    "                    interpolationRange = list(range(index - 1, index + width + 1, 1))\n",
    "                    for i in interpolationRange:\n",
    "                        arr[i] = cspline(i)\n",
    "\n",
    "            # move index forward past gap, continue searching\n",
    "            index += width\n",
    "\n",
    "        # no null gap, so continue searching\n",
    "        else:\n",
    "            index += 1\n",
    "    \n",
    "    # replacing arr in df with arr with interpolated values\n",
    "    df[col] = arr\n",
    "\n",
    "# adding year, month, day, and hour columns\n",
    "df[\"Year\"] = df[\"DateTime\"].dt.year\n",
    "df[\"Month\"] = df[\"DateTime\"].dt.month\n",
    "df[\"Week Day\"] = df[\"DateTime\"].dt.dayofweek\n",
    "df[\"Hour\"] = df[\"DateTime\"].dt.hour\n",
    "\n",
    "# saving new interpolated data\n",
    "df.to_csv(\"Small Gap Imputed Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n",
    "\n",
    "desiredColumns = [\"SWTP Total Influent Flow\", \"James Gauge Height (ft)\", \"Wilsons Gauge Height (ft)\",\n",
    "                  \"Springfield Plateau Aquifer Depth to Water Level (ft)\", \"Ozark Aquifer Depth to Water Level (ft)\",\n",
    "                  \"HourlyStationPressure\", \"Fire 168 Hour Rainfall Aggregate\", \"AT&T 168 Hour Rainfall Aggregate\",\n",
    "                   \"Field 168 Hour Rainfall Aggregate\", \"Bingham 168 Hour Rainfall Aggregate\",\n",
    "                   \"Hour\", \"Month\", \"Year\", \"Week Day\"]\n",
    "df = pd.read_csv(\"Small Gap Imputed Data.csv\", usecols=desiredColumns)\n",
    "data = df.to_numpy()\n",
    "imputer = MissForest(criterion=\"squared_error\", n_estimators=80)\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "imputed_df = pd.DataFrame(data_imputed, columns=df.columns)\n",
    "dates = pd.read_csv(\"Small Gap Imputed Data.csv\", usecols=[\"DateTime\"])\n",
    "imputed_df[\"DateTime\"] = np.array(dates[\"DateTime\"])\n",
    "imputed_df.to_csv(\"All Gap Imputed Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change the feature variable in the following and run the cell to see interpolated values\n",
    "##### The SWTP Total Influent Flow looks solid, but the Aquifer features do not look to be interpolated well\n",
    "##### We should try to interpolate those in a different way, I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "def makeNullRects(dates, y):\n",
    "    '''This function returns a list of matplotlib.patches.Rectangles where\n",
    "    np.nan values are present in the y array. If values are consecutive,\n",
    "    the rectangles will widen as needed.\n",
    "    Note that this function is made for a figure with an x-axis of dates\n",
    "    Input:\n",
    "        dates: x axis date time values\n",
    "        y: y axis range values as np.array, contains np.nan values\n",
    "\n",
    "    Returns:\n",
    "        list of matplotlib.patches.Rectangles located where\n",
    "        y has np.nan values.\n",
    "\n",
    "    Rectangle Parameters in function:\n",
    "        opacityCoeff: how solid rectangles appear\n",
    "        longRectColor: the color of the rectangles with >=7 width\n",
    "        shortRectColor: the color of the rectanges with <7 width\n",
    "    '''\n",
    "    # setting up rectangle parameters\n",
    "    opacityCoeff = 0.5\n",
    "    longRectColor = \"red\"\n",
    "    shortRectColor = \"magenta\"\n",
    "\n",
    "    # prep work for creating rectangles for nan values\n",
    "    index = 0\n",
    "    yMax = np.nanmax(y)\n",
    "    yMin = np.nanmin(y)\n",
    "    rectHeight = yMax - yMin\n",
    "    yRectCoor = yMin\n",
    "    allRects = []   # this is what will be returned\n",
    "\n",
    "    # creating rectangle patches\n",
    "    while index < len(y):\n",
    "\n",
    "        # if nan exists, then need to create a rectangle patch\n",
    "        if np.isnan(y[index]):\n",
    "            xRectCoorIndex = index - 1\n",
    "\n",
    "            # condition for if first y value is nan\n",
    "            if index == 0:\n",
    "                xRectCoorIndex += 1\n",
    "            \n",
    "            # condition for if last y value is nan, assumes y is not len 2\n",
    "            elif index + 1 == len(y):\n",
    "                xRectCoor = mdates.date2num(dates[xRectCoorIndex])\n",
    "                coords = (xRectCoor, yRectCoor)\n",
    "                width = mdates.date2num(dates[xRectCoorIndex + 1]) - mdates.date2num(dates[xRectCoorIndex])\n",
    "                allRects.append(mpatches.Rectangle(coords, width, rectHeight, color=shortRectColor, alpha=opacityCoeff))\n",
    "                break\n",
    "                \n",
    "            # all other cases\n",
    "            xRectCoor = mdates.date2num(dates[xRectCoorIndex])\n",
    "\n",
    "            # checking finding how long the rectangle needs to be--how many consecutive null values\n",
    "            index += 1\n",
    "            while np.isnan(y[index]):\n",
    "                index += 1\n",
    "            rightEdgeIndex = mdates.date2num(dates[index])\n",
    "\n",
    "            # making rectangle\n",
    "            coords = (xRectCoor, yRectCoor)\n",
    "            width = rightEdgeIndex - xRectCoor\n",
    "            color = shortRectColor\n",
    "            if index - xRectCoorIndex > 5:\n",
    "                color = longRectColor\n",
    "            allRects.append(mpatches.Rectangle(coords, width, rectHeight, color=color, alpha=opacityCoeff))\n",
    "\n",
    "        else:\n",
    "            index += 1\n",
    "\n",
    "    return allRects\n",
    "\n",
    "def visualizeMissingValues(dates, arr, fig, ax):\n",
    "    '''This function plots an array of values with datetime x axis values onto\n",
    "    a given axis, showing patches of null values if present.\n",
    "    '''\n",
    "    ax.plot(dates, arr)\n",
    "\n",
    "    rects = makeNullRects(dates, arr)\n",
    "    for rect in rects:\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    formatter = mdates.ConciseDateFormatter(ax.xaxis.get_major_locator(), formats=[\"%Y\", \"%Y-%b\", \"%b-%d\", \"%d %H:%M\", \"%d %H:%M\", \"%H:%M\"])\n",
    "    locator = mdates.AutoDateLocator()\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    return fig, ax\n",
    "\n",
    "# getting data\n",
    "originalDf = pd.read_csv(\"Joined Influent and Rainfall and Weather and Groundwater and Creek Gauge.csv\", parse_dates=[\"DateTime\"])\n",
    "imputedDf = pd.read_csv(\"All Gap Imputed Data.csv\", parse_dates=[\"DateTime\"])\n",
    "\n",
    "\n",
    "# feature to visualize\n",
    "\n",
    "feature = \"SWTP Total Influent Flow\"\n",
    "# feature = \"Ozark Aquifer Depth to Water Level (ft)\"\n",
    "# feature = \"Springfield Plateau Aquifer Depth to Water Level (ft)\"\n",
    "# feature = \"James Gauge Height (ft)\"\n",
    "# feature = \"Wilsons Gauge Height (ft)\"\n",
    "# feature = \"Fire 168 Hour Rainfall Aggregate\"\n",
    "\n",
    "# plotting original data and missing gaps\n",
    "arr = np.array(originalDf[feature])\n",
    "fig, ax = plt.subplots()\n",
    "fig, ax = visualizeMissingValues(originalDf[\"DateTime\"], arr, fig, ax)\n",
    "\n",
    "# plotting interpolated data\n",
    "imputedArr = np.array(imputedDf[feature])\n",
    "index = 0\n",
    "dates = np.array(imputedDf[\"DateTime\"])\n",
    "while index < len(arr):                                 # looping through arr since it has the null values\n",
    "    if np.isnan(arr[index]):\n",
    "        # getting the width of the null area\n",
    "        lenForward = 0\n",
    "        while np.isnan(arr[index + lenForward]):\n",
    "            lenForward += 1\n",
    "\n",
    "        # domain to plot is [index-1, index+lenforward+1]\n",
    "        domain = list(range(index-1, index+lenForward+2))\n",
    "        datesToPlot = [dates[i] for i in domain]\n",
    "        pointsToPlot = [imputedArr[i] for i in domain]\n",
    "        ax.plot(datesToPlot, pointsToPlot, \"g--\")       # green dashed line\n",
    "\n",
    "        # moving index forward past null gap\n",
    "        index += lenForward\n",
    "    else:\n",
    "        index += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18d1565e3dd2a1a1180dd629712b39ff168054eb513fda549cd851c01d6423bb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
